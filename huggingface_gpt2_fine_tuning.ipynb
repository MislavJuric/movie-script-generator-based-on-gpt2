{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3bface5eda5d42bfb8f0ee6cbd0881ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e81b4d415d5247b5a9b50bb0e49a64ac",
              "IPY_MODEL_9ea3e94b11f249cc980fc1a304cd6611",
              "IPY_MODEL_0d00c0c65fd94b4a9cdc00a1a60318e4"
            ],
            "layout": "IPY_MODEL_56b13f9db104451ea666f03c73f47cdb"
          }
        },
        "e81b4d415d5247b5a9b50bb0e49a64ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f933314569454dc0b219bdac85b4b342",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf2f9b6966f4758a8a20e42ab5af9c5",
            "value": "Resolving data files: 100%"
          }
        },
        "9ea3e94b11f249cc980fc1a304cd6611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98cf099d251b4f35a389c40c11f8c53f",
            "max": 3003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_746ecc11a36642c58cad5ad8a5309d98",
            "value": 3003
          }
        },
        "0d00c0c65fd94b4a9cdc00a1a60318e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ab66d52eb344278dd8959d4fbf0fe5",
            "placeholder": "​",
            "style": "IPY_MODEL_1091f4c242c643a7bb5f1247332af4d9",
            "value": " 3003/3003 [00:01&lt;00:00, 2591.78it/s]"
          }
        },
        "56b13f9db104451ea666f03c73f47cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f933314569454dc0b219bdac85b4b342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf2f9b6966f4758a8a20e42ab5af9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98cf099d251b4f35a389c40c11f8c53f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746ecc11a36642c58cad5ad8a5309d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9ab66d52eb344278dd8959d4fbf0fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1091f4c242c643a7bb5f1247332af4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7188145901f1424397a9cd8460276449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cd55c6a61e14e4395b9d86ea64afc46",
              "IPY_MODEL_92fd2eed4f224fcb9e3cd88cb48c841e",
              "IPY_MODEL_bef8f5e1e4c54dacb6a351e961f7fb0a"
            ],
            "layout": "IPY_MODEL_9f029c09f66446b2811f2df3a0f2d98e"
          }
        },
        "4cd55c6a61e14e4395b9d86ea64afc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed02c40571c9436483a24b96e45c645b",
            "placeholder": "​",
            "style": "IPY_MODEL_f0a8bb26d3534830bb2e53621de6af70",
            "value": "Downloading data files: 100%"
          }
        },
        "92fd2eed4f224fcb9e3cd88cb48c841e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e582f8f21091496cbef8efee7f18f7ea",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f8f76d2e5064d04a97c5cee8155c9af",
            "value": 1
          }
        },
        "bef8f5e1e4c54dacb6a351e961f7fb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289be8dcee2c4d94ad3d3e141335e3d5",
            "placeholder": "​",
            "style": "IPY_MODEL_8e06d9b893fa40f68c4529943fd9d43c",
            "value": " 1/1 [00:00&lt;00:00,  1.89it/s]"
          }
        },
        "9f029c09f66446b2811f2df3a0f2d98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed02c40571c9436483a24b96e45c645b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a8bb26d3534830bb2e53621de6af70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e582f8f21091496cbef8efee7f18f7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8f76d2e5064d04a97c5cee8155c9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "289be8dcee2c4d94ad3d3e141335e3d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e06d9b893fa40f68c4529943fd9d43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f089b52f1b249e6a0318fb438dae9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbce32b89ae34beeb31e7847ad19c97f",
              "IPY_MODEL_ac023fa4ab46487e82877d79eb119771",
              "IPY_MODEL_9df7c907dd79420c8291a7e07b973130"
            ],
            "layout": "IPY_MODEL_5b58249f61454494b47b1492f40db29e"
          }
        },
        "fbce32b89ae34beeb31e7847ad19c97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f22be802fa4595b7d7ea387a51de07",
            "placeholder": "​",
            "style": "IPY_MODEL_53e2497a6eb0499091bc6d84d4ae1d7d",
            "value": "Extracting data files: 100%"
          }
        },
        "ac023fa4ab46487e82877d79eb119771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d33c0cdb0029406f83d1e7ba30ba8b88",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e0480aa6b1145088337bdec4ca2a12b",
            "value": 1
          }
        },
        "9df7c907dd79420c8291a7e07b973130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ffea0fae054cf0bfd104bd696dae37",
            "placeholder": "​",
            "style": "IPY_MODEL_968f09c6d0df46e9874a7d11dce781ef",
            "value": " 1/1 [00:16&lt;00:00, 16.49s/it]"
          }
        },
        "5b58249f61454494b47b1492f40db29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f22be802fa4595b7d7ea387a51de07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e2497a6eb0499091bc6d84d4ae1d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d33c0cdb0029406f83d1e7ba30ba8b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0480aa6b1145088337bdec4ca2a12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85ffea0fae054cf0bfd104bd696dae37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968f09c6d0df46e9874a7d11dce781ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ff9a9f603df4f68b84d7fbda75678d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43c2a28527734dc38924ea5b2e1362d6",
              "IPY_MODEL_2a604103d7ac4368a11c5dfc3924fab1",
              "IPY_MODEL_faec57b8b3a541ef908eda708a14e806"
            ],
            "layout": "IPY_MODEL_05301a4cbd4a466fba3ba04804094a50"
          }
        },
        "43c2a28527734dc38924ea5b2e1362d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa3c9f6865c44508b708110d5665248",
            "placeholder": "​",
            "style": "IPY_MODEL_c3081894644b4cab9e47021d3d37b816",
            "value": ""
          }
        },
        "2a604103d7ac4368a11c5dfc3924fab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2212ae5dbd8d40098bb47c64b1068719",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_328853a26da14304a5860557e1cc63c2",
            "value": 1
          }
        },
        "faec57b8b3a541ef908eda708a14e806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d90a2e9a3ed64372a59f37e06762a5cc",
            "placeholder": "​",
            "style": "IPY_MODEL_36bbe2d0454b466893ccec086c05b5d2",
            "value": " 2985/? [00:14&lt;00:00, 190.44 tables/s]"
          }
        },
        "05301a4cbd4a466fba3ba04804094a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0aa3c9f6865c44508b708110d5665248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3081894644b4cab9e47021d3d37b816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2212ae5dbd8d40098bb47c64b1068719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "328853a26da14304a5860557e1cc63c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d90a2e9a3ed64372a59f37e06762a5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36bbe2d0454b466893ccec086c05b5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87f438b80812412b94a8dcd339b099b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26084c6d8918421cbe681433612e75d5",
              "IPY_MODEL_2e1b7f0a4bbe4f5dab17217c5d386372",
              "IPY_MODEL_fddfad471e824883afa59287b70927c8"
            ],
            "layout": "IPY_MODEL_13f53215b97a4f1ea2d7a2d1ea78421f"
          }
        },
        "26084c6d8918421cbe681433612e75d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b90e037b064eebb49043b09433a9f4",
            "placeholder": "​",
            "style": "IPY_MODEL_8e882f6b6a1243b8b491b93722610752",
            "value": "100%"
          }
        },
        "2e1b7f0a4bbe4f5dab17217c5d386372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d7477ab53a04925a8f931d147716728",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ec2dc3b43e463d9282d7f34b1196b1",
            "value": 1
          }
        },
        "fddfad471e824883afa59287b70927c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5e89a3a93c44ddbcdfbf386cc3337f",
            "placeholder": "​",
            "style": "IPY_MODEL_5c280b4eb1574891972515c66f0ab800",
            "value": " 1/1 [00:00&lt;00:00, 14.25it/s]"
          }
        },
        "13f53215b97a4f1ea2d7a2d1ea78421f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b90e037b064eebb49043b09433a9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e882f6b6a1243b8b491b93722610752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d7477ab53a04925a8f931d147716728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ec2dc3b43e463d9282d7f34b1196b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd5e89a3a93c44ddbcdfbf386cc3337f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c280b4eb1574891972515c66f0ab800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "523bb15dce994ad49a2ef46fd751d5f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d5006266644dac9f9b1a8559b0aef2",
              "IPY_MODEL_50879bc1db1c4fb2bcc6a1f70f0c5926",
              "IPY_MODEL_64edf57b928643f8942fa60bf8529550"
            ],
            "layout": "IPY_MODEL_20ee990bd9ea4d629e3092f782e15fd9"
          }
        },
        "b5d5006266644dac9f9b1a8559b0aef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc5e7b921e2b42a190af6025f9999840",
            "placeholder": "​",
            "style": "IPY_MODEL_c3453898f6f74c71b45a19d0e3c65526",
            "value": "Downloading: 100%"
          }
        },
        "50879bc1db1c4fb2bcc6a1f70f0c5926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_612edd4bcea3459b89be9f538fee0bee",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf3bec9a0f69439b844de1aa56f5c0b7",
            "value": 665
          }
        },
        "64edf57b928643f8942fa60bf8529550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06862c3356df48d5acc067b725361f86",
            "placeholder": "​",
            "style": "IPY_MODEL_9d7a1a1e5ff8421189074bf1fc18388b",
            "value": " 665/665 [00:00&lt;00:00, 26.3kB/s]"
          }
        },
        "20ee990bd9ea4d629e3092f782e15fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc5e7b921e2b42a190af6025f9999840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3453898f6f74c71b45a19d0e3c65526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "612edd4bcea3459b89be9f538fee0bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf3bec9a0f69439b844de1aa56f5c0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06862c3356df48d5acc067b725361f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7a1a1e5ff8421189074bf1fc18388b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82e9c2b934394c76b0b610bc166fb36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_234d50f5d3c14b7a8cd3a0341ad98b87",
              "IPY_MODEL_c66e3db2b4604f2abb7e63430feeb87b",
              "IPY_MODEL_363300b915774409a364475f1061813b"
            ],
            "layout": "IPY_MODEL_4d9426bb37e14ce2b24baaa0decb90a5"
          }
        },
        "234d50f5d3c14b7a8cd3a0341ad98b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_768b764a25bd4bf1b84c4424a1393cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_5e9a0212a1cc4731b54b6b1b4c675c90",
            "value": "Downloading: 100%"
          }
        },
        "c66e3db2b4604f2abb7e63430feeb87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce2b35c762e948efac2eb2f1b1c7a85e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f02595585306464393bc3c3bfb63858d",
            "value": 1042301
          }
        },
        "363300b915774409a364475f1061813b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60cd0cde6bb845a195e5ef1136240d65",
            "placeholder": "​",
            "style": "IPY_MODEL_15c4681fdf4048829fbae939283835ee",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "4d9426bb37e14ce2b24baaa0decb90a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768b764a25bd4bf1b84c4424a1393cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9a0212a1cc4731b54b6b1b4c675c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce2b35c762e948efac2eb2f1b1c7a85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02595585306464393bc3c3bfb63858d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60cd0cde6bb845a195e5ef1136240d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c4681fdf4048829fbae939283835ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "968c4a1fc678494f836e5662ace281c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a067c6853504993841c52a4a295eb51",
              "IPY_MODEL_f30c9e09ee1f4ff8aefacce893fe1bbc",
              "IPY_MODEL_c4dbd3e44a624870991d27a2010d23db"
            ],
            "layout": "IPY_MODEL_2bd42ba6c03743b3813d551e226d0188"
          }
        },
        "2a067c6853504993841c52a4a295eb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7819fce6ba2847f0837d9db927851a43",
            "placeholder": "​",
            "style": "IPY_MODEL_25171b4627e747968fe0a030254fa06b",
            "value": "Downloading: 100%"
          }
        },
        "f30c9e09ee1f4ff8aefacce893fe1bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f7db9068c34f9d8084fea13be483cc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3853403833dc4ef1b179cbdc080a6e0c",
            "value": 456318
          }
        },
        "c4dbd3e44a624870991d27a2010d23db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a7e20e922f74be1a2ffe8c5aa92c613",
            "placeholder": "​",
            "style": "IPY_MODEL_e57ea02c81b14fa99671553fdd769e1f",
            "value": " 456k/456k [00:00&lt;00:00, 1.69MB/s]"
          }
        },
        "2bd42ba6c03743b3813d551e226d0188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7819fce6ba2847f0837d9db927851a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25171b4627e747968fe0a030254fa06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f7db9068c34f9d8084fea13be483cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3853403833dc4ef1b179cbdc080a6e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a7e20e922f74be1a2ffe8c5aa92c613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57ea02c81b14fa99671553fdd769e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f18bede8c2484437a80140d6e9cddaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_657c363ccc6e470c83e67a891cddf058",
              "IPY_MODEL_ea4a1f580c964a748af2245a3f2ecbe0",
              "IPY_MODEL_a62cbfb646154b73bda45d4d22cc10fd"
            ],
            "layout": "IPY_MODEL_cf8d4d4605894d2180fc66f94701ac76"
          }
        },
        "657c363ccc6e470c83e67a891cddf058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54eea4afe0864768a17ab61d4df07f03",
            "placeholder": "​",
            "style": "IPY_MODEL_a50d828d99c5432084ff2418330e4769",
            "value": "Downloading: 100%"
          }
        },
        "ea4a1f580c964a748af2245a3f2ecbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ee2bb2297047ce897167835fc27a40",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ece224b1258401cb9559185a86674f2",
            "value": 1355256
          }
        },
        "a62cbfb646154b73bda45d4d22cc10fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87aa7c3ea0384935b95994e4a67572ad",
            "placeholder": "​",
            "style": "IPY_MODEL_4baeb11763df40a1ac95479c06101eaf",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "cf8d4d4605894d2180fc66f94701ac76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54eea4afe0864768a17ab61d4df07f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50d828d99c5432084ff2418330e4769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ee2bb2297047ce897167835fc27a40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ece224b1258401cb9559185a86674f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87aa7c3ea0384935b95994e4a67572ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4baeb11763df40a1ac95479c06101eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a460925d6461448d8bd3980369690f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed308cba93b842deab167bee9566b8ac",
              "IPY_MODEL_c4a8bdb27f544eb7bf5e793c23ac6f03",
              "IPY_MODEL_55c9d9a6248d4661b0da8a8e5381461e"
            ],
            "layout": "IPY_MODEL_3e99ff2cfe50464eb00e76c5f6449e85"
          }
        },
        "ed308cba93b842deab167bee9566b8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_196e6d477c3149a7bcbe426963360d72",
            "placeholder": "​",
            "style": "IPY_MODEL_cdc256893db2447097cc668dc039f950",
            "value": "100%"
          }
        },
        "c4a8bdb27f544eb7bf5e793c23ac6f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dfa823ab508453f944e8d1685c3bfca",
            "max": 18827,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d28ba3f63f0c47aeba1044b4fe6b8d05",
            "value": 18826
          }
        },
        "55c9d9a6248d4661b0da8a8e5381461e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2a1e9a9d9c458e85c4e37bf92d8b3b",
            "placeholder": "​",
            "style": "IPY_MODEL_19594b85244d427782c53ce6afd51e77",
            "value": " 18826/18827 [1:42:22&lt;00:00,  2.94ba/s]"
          }
        },
        "3e99ff2cfe50464eb00e76c5f6449e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196e6d477c3149a7bcbe426963360d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc256893db2447097cc668dc039f950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dfa823ab508453f944e8d1685c3bfca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28ba3f63f0c47aeba1044b4fe6b8d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da2a1e9a9d9c458e85c4e37bf92d8b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19594b85244d427782c53ce6afd51e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50b347481a9241dcb5a7c2143b550b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8e1b2737ebb4b2f8b020ae37fdfb18f",
              "IPY_MODEL_68c9ed9957f441e3b033e7405b2228c7",
              "IPY_MODEL_de4fc6a2eb0149909be433da37234802"
            ],
            "layout": "IPY_MODEL_3f6822995fdb48059370658a05e7a75e"
          }
        },
        "a8e1b2737ebb4b2f8b020ae37fdfb18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba3e532ae1f4395bb381087b64d524f",
            "placeholder": "​",
            "style": "IPY_MODEL_f0c1b2df436840b1aa39293221c729d9",
            "value": "Downloading: 100%"
          }
        },
        "68c9ed9957f441e3b033e7405b2228c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3b57745d5f40d588e9ade87f3c17d3",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22b8c7bdcd224fc1b2007cc35ceca352",
            "value": 548118077
          }
        },
        "de4fc6a2eb0149909be433da37234802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce6c131c9414d48af5a02570186de1a",
            "placeholder": "​",
            "style": "IPY_MODEL_2b40f5ed303f41c6b60ab0941ef7a691",
            "value": " 548M/548M [00:08&lt;00:00, 62.6MB/s]"
          }
        },
        "3f6822995fdb48059370658a05e7a75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba3e532ae1f4395bb381087b64d524f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c1b2df436840b1aa39293221c729d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f3b57745d5f40d588e9ade87f3c17d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b8c7bdcd224fc1b2007cc35ceca352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cce6c131c9414d48af5a02570186de1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b40f5ed303f41c6b60ab0941ef7a691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8069f2efbc8b4589935db063e602d366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_368443be0be84b27a3cf85be02c88924",
              "IPY_MODEL_2e2551de9f0345e68ded3f58b446968e",
              "IPY_MODEL_e49524a567c140deb8d0a9fbed74ead7"
            ],
            "layout": "IPY_MODEL_37bd8284ddea48f69d44c7c7400e8c03"
          }
        },
        "368443be0be84b27a3cf85be02c88924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cad24cca1f041d282daaf217efb8732",
            "placeholder": "​",
            "style": "IPY_MODEL_ae38246c25d444b9943bccfc21b32131",
            "value": "Downloading: 100%"
          }
        },
        "2e2551de9f0345e68ded3f58b446968e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e51a5f51cc3c4e508940bcd8311b81fc",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2ceac7719e84a749648fbbd8dc12c35",
            "value": 1042301
          }
        },
        "e49524a567c140deb8d0a9fbed74ead7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec79a5de8d54c239bfc297b7a07b312",
            "placeholder": "​",
            "style": "IPY_MODEL_aacda671b11f49cbaf88f44e58e3d9e4",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.43MB/s]"
          }
        },
        "37bd8284ddea48f69d44c7c7400e8c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cad24cca1f041d282daaf217efb8732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae38246c25d444b9943bccfc21b32131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e51a5f51cc3c4e508940bcd8311b81fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ceac7719e84a749648fbbd8dc12c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec79a5de8d54c239bfc297b7a07b312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aacda671b11f49cbaf88f44e58e3d9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3322698af0314def94acff41262e27ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7d9e8485f5e4cec82916cac4ea90ba2",
              "IPY_MODEL_01038cedc4f64ce28fc837a74dd7b6dd",
              "IPY_MODEL_bd2baf1e29ba41848f0b4d22a35f0b84"
            ],
            "layout": "IPY_MODEL_b319b9976ba94a41b287eb2d25f10d68"
          }
        },
        "e7d9e8485f5e4cec82916cac4ea90ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7814101e19b646bfb7427cfdc014bb76",
            "placeholder": "​",
            "style": "IPY_MODEL_c5198aa9122641ac93566d2286f24e23",
            "value": "Downloading: 100%"
          }
        },
        "01038cedc4f64ce28fc837a74dd7b6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c2f9ad9c0141e7926a894d46ab8660",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0c3159e563541c7806120ef8bf945eb",
            "value": 456318
          }
        },
        "bd2baf1e29ba41848f0b4d22a35f0b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d622320201bd4191b47441bbda903cde",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b5e2e76ebb43b889929c5f72d80646",
            "value": " 456k/456k [00:00&lt;00:00, 1.16MB/s]"
          }
        },
        "b319b9976ba94a41b287eb2d25f10d68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7814101e19b646bfb7427cfdc014bb76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5198aa9122641ac93566d2286f24e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44c2f9ad9c0141e7926a894d46ab8660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c3159e563541c7806120ef8bf945eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d622320201bd4191b47441bbda903cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b5e2e76ebb43b889929c5f72d80646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3905c09c9f2e45c68ebecc2c670989c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_215d2c56a8ea418c9a52f1bf8e1c445e",
              "IPY_MODEL_d13a18f929c443c892acfd2262eeae6a",
              "IPY_MODEL_ed8cfaad3d804b598aa08f32e0007632"
            ],
            "layout": "IPY_MODEL_59561f4704244775b9588a31f59ceeda"
          }
        },
        "215d2c56a8ea418c9a52f1bf8e1c445e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5f67c5f6d44a1cb822307a99b1b4d5",
            "placeholder": "​",
            "style": "IPY_MODEL_f0c3bbd2dda64ba596b1398d8b41a6d4",
            "value": "Downloading: 100%"
          }
        },
        "d13a18f929c443c892acfd2262eeae6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab661944b7ca487db619d5c146a38db5",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c7d13118b9849029a3556cd4a2d5407",
            "value": 665
          }
        },
        "ed8cfaad3d804b598aa08f32e0007632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44337b26ea1843f6bd3e9d2934ccc07e",
            "placeholder": "​",
            "style": "IPY_MODEL_99d3b2039bcc4a8baf93f769a2bb6c26",
            "value": " 665/665 [00:00&lt;00:00, 25.1kB/s]"
          }
        },
        "59561f4704244775b9588a31f59ceeda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5f67c5f6d44a1cb822307a99b1b4d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c3bbd2dda64ba596b1398d8b41a6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab661944b7ca487db619d5c146a38db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7d13118b9849029a3556cd4a2d5407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44337b26ea1843f6bd3e9d2934ccc07e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d3b2039bcc4a8baf93f769a2bb6c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d602d44f95c64f4b85ccfbc56a81aa7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90847868ddb24c29989499c8c1003c5c",
              "IPY_MODEL_128d056cb2c244d8848459da3ed32102",
              "IPY_MODEL_8e4f2b8033c74f45a810fb5837ba3731"
            ],
            "layout": "IPY_MODEL_6b4fa79ddb7444f192a81bea3ba54230"
          }
        },
        "90847868ddb24c29989499c8c1003c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbfffa4f583d4365819790ddf0466044",
            "placeholder": "​",
            "style": "IPY_MODEL_7c83471beec14d378954c30861f36059",
            "value": "Downloading: 100%"
          }
        },
        "128d056cb2c244d8848459da3ed32102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c1aea51401e48e9b0e2d142837c6514",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1617563e95f421cb0f54497e7316644",
            "value": 548118077
          }
        },
        "8e4f2b8033c74f45a810fb5837ba3731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d68ff22fc8465c8c887cf68e7c110d",
            "placeholder": "​",
            "style": "IPY_MODEL_4b3a56a86054444380a6218d9b4197f8",
            "value": " 548M/548M [00:13&lt;00:00, 40.1MB/s]"
          }
        },
        "6b4fa79ddb7444f192a81bea3ba54230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfffa4f583d4365819790ddf0466044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c83471beec14d378954c30861f36059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c1aea51401e48e9b0e2d142837c6514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1617563e95f421cb0f54497e7316644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1d68ff22fc8465c8c887cf68e7c110d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3a56a86054444380a6218d9b4197f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face GPT2 fine-tuning"
      ],
      "metadata": {
        "id": "GPhgeJc8C7Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHS45HIlAvpw",
        "outputId": "c0885db3-1ea6-4fa4-b61e-cff8de993cf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 84.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 75.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjR_HI5QdYqX",
        "outputId": "270ec51e-5716-40d7-9d9b-f26ded53a5f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 90.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 84.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 78.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face fine-tuning"
      ],
      "metadata": {
        "id": "YDgguQuzcU1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From https://huggingface.co/docs/datasets/nlp_load:"
      ],
      "metadata": {
        "id": "mc9OhKf1cY9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "u0w0e_8Ucbrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32bc3e4c-60a5-4bde-9c39-5fab30e55991",
        "id": "QBim-XONdo-o"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIRECTORY = \"/content/drive/MyDrive/Movie Script Generator/dataset/txt_pruned\""
      ],
      "metadata": {
        "id": "mLaSc9VOdo-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"text\", data_dir=DATASET_DIRECTORY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "3bface5eda5d42bfb8f0ee6cbd0881ac",
            "e81b4d415d5247b5a9b50bb0e49a64ac",
            "9ea3e94b11f249cc980fc1a304cd6611",
            "0d00c0c65fd94b4a9cdc00a1a60318e4",
            "56b13f9db104451ea666f03c73f47cdb",
            "f933314569454dc0b219bdac85b4b342",
            "7cf2f9b6966f4758a8a20e42ab5af9c5",
            "98cf099d251b4f35a389c40c11f8c53f",
            "746ecc11a36642c58cad5ad8a5309d98",
            "c9ab66d52eb344278dd8959d4fbf0fe5",
            "1091f4c242c643a7bb5f1247332af4d9",
            "7188145901f1424397a9cd8460276449",
            "4cd55c6a61e14e4395b9d86ea64afc46",
            "92fd2eed4f224fcb9e3cd88cb48c841e",
            "bef8f5e1e4c54dacb6a351e961f7fb0a",
            "9f029c09f66446b2811f2df3a0f2d98e",
            "ed02c40571c9436483a24b96e45c645b",
            "f0a8bb26d3534830bb2e53621de6af70",
            "e582f8f21091496cbef8efee7f18f7ea",
            "4f8f76d2e5064d04a97c5cee8155c9af",
            "289be8dcee2c4d94ad3d3e141335e3d5",
            "8e06d9b893fa40f68c4529943fd9d43c",
            "1f089b52f1b249e6a0318fb438dae9ea",
            "fbce32b89ae34beeb31e7847ad19c97f",
            "ac023fa4ab46487e82877d79eb119771",
            "9df7c907dd79420c8291a7e07b973130",
            "5b58249f61454494b47b1492f40db29e",
            "51f22be802fa4595b7d7ea387a51de07",
            "53e2497a6eb0499091bc6d84d4ae1d7d",
            "d33c0cdb0029406f83d1e7ba30ba8b88",
            "9e0480aa6b1145088337bdec4ca2a12b",
            "85ffea0fae054cf0bfd104bd696dae37",
            "968f09c6d0df46e9874a7d11dce781ef",
            "7ff9a9f603df4f68b84d7fbda75678d7",
            "43c2a28527734dc38924ea5b2e1362d6",
            "2a604103d7ac4368a11c5dfc3924fab1",
            "faec57b8b3a541ef908eda708a14e806",
            "05301a4cbd4a466fba3ba04804094a50",
            "0aa3c9f6865c44508b708110d5665248",
            "c3081894644b4cab9e47021d3d37b816",
            "2212ae5dbd8d40098bb47c64b1068719",
            "328853a26da14304a5860557e1cc63c2",
            "d90a2e9a3ed64372a59f37e06762a5cc",
            "36bbe2d0454b466893ccec086c05b5d2",
            "87f438b80812412b94a8dcd339b099b4",
            "26084c6d8918421cbe681433612e75d5",
            "2e1b7f0a4bbe4f5dab17217c5d386372",
            "fddfad471e824883afa59287b70927c8",
            "13f53215b97a4f1ea2d7a2d1ea78421f",
            "69b90e037b064eebb49043b09433a9f4",
            "8e882f6b6a1243b8b491b93722610752",
            "2d7477ab53a04925a8f931d147716728",
            "a6ec2dc3b43e463d9282d7f34b1196b1",
            "dd5e89a3a93c44ddbcdfbf386cc3337f",
            "5c280b4eb1574891972515c66f0ab800"
          ]
        },
        "id": "F-yfOWlBce1i",
        "outputId": "6b64c55c-281f-44c4-d40b-c086eba256aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/3003 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bface5eda5d42bfb8f0ee6cbd0881ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-a787a67b7bc4768e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-a787a67b7bc4768e/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7188145901f1424397a9cd8460276449"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f089b52f1b249e6a0318fb438dae9ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ff9a9f603df4f68b84d7fbda75678d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-a787a67b7bc4768e/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87f438b80812412b94a8dcd339b099b4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTMhUm1hch6E",
        "outputId": "76a0b557-e45d-4699-c8b5-951e06c14994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 18826310\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLLzBI_ocjnb",
        "outputId": "fa46cc6e-3f6a-411c-c087-ae85672ecc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'ACTION | \\ton a tray table.  Crumpled Czech bills and coins are on it. '}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "U_2vNvjOcldg",
        "outputId": "61bdca3a-0d9a-43b9-9c63-7de37b27810f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-56acce8eb66a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedSplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             available_suggested_splits = [\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From https://huggingface.co/docs/transformers/training:"
      ],
      "metadata": {
        "id": "OdLJlUwgcn-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "3UstcVpEcpK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "523bb15dce994ad49a2ef46fd751d5f6",
            "b5d5006266644dac9f9b1a8559b0aef2",
            "50879bc1db1c4fb2bcc6a1f70f0c5926",
            "64edf57b928643f8942fa60bf8529550",
            "20ee990bd9ea4d629e3092f782e15fd9",
            "cc5e7b921e2b42a190af6025f9999840",
            "c3453898f6f74c71b45a19d0e3c65526",
            "612edd4bcea3459b89be9f538fee0bee",
            "cf3bec9a0f69439b844de1aa56f5c0b7",
            "06862c3356df48d5acc067b725361f86",
            "9d7a1a1e5ff8421189074bf1fc18388b",
            "82e9c2b934394c76b0b610bc166fb36d",
            "234d50f5d3c14b7a8cd3a0341ad98b87",
            "c66e3db2b4604f2abb7e63430feeb87b",
            "363300b915774409a364475f1061813b",
            "4d9426bb37e14ce2b24baaa0decb90a5",
            "768b764a25bd4bf1b84c4424a1393cc4",
            "5e9a0212a1cc4731b54b6b1b4c675c90",
            "ce2b35c762e948efac2eb2f1b1c7a85e",
            "f02595585306464393bc3c3bfb63858d",
            "60cd0cde6bb845a195e5ef1136240d65",
            "15c4681fdf4048829fbae939283835ee",
            "968c4a1fc678494f836e5662ace281c7",
            "2a067c6853504993841c52a4a295eb51",
            "f30c9e09ee1f4ff8aefacce893fe1bbc",
            "c4dbd3e44a624870991d27a2010d23db",
            "2bd42ba6c03743b3813d551e226d0188",
            "7819fce6ba2847f0837d9db927851a43",
            "25171b4627e747968fe0a030254fa06b",
            "21f7db9068c34f9d8084fea13be483cc",
            "3853403833dc4ef1b179cbdc080a6e0c",
            "4a7e20e922f74be1a2ffe8c5aa92c613",
            "e57ea02c81b14fa99671553fdd769e1f",
            "f18bede8c2484437a80140d6e9cddaaf",
            "657c363ccc6e470c83e67a891cddf058",
            "ea4a1f580c964a748af2245a3f2ecbe0",
            "a62cbfb646154b73bda45d4d22cc10fd",
            "cf8d4d4605894d2180fc66f94701ac76",
            "54eea4afe0864768a17ab61d4df07f03",
            "a50d828d99c5432084ff2418330e4769",
            "a1ee2bb2297047ce897167835fc27a40",
            "1ece224b1258401cb9559185a86674f2",
            "87aa7c3ea0384935b95994e4a67572ad",
            "4baeb11763df40a1ac95479c06101eaf"
          ]
        },
        "id": "Jb_S06Czcqzh",
        "outputId": "dc3cb6fb-a9c5-4085-e217-a4bada17b108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "523bb15dce994ad49a2ef46fd751d5f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82e9c2b934394c76b0b610bc166fb36d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "968c4a1fc678494f836e5662ace281c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f18bede8c2484437a80140d6e9cddaaf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '<|pad|>'}) # added so that I don't get an error when tokenizing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7NqBWwfcsKl",
        "outputId": "deb3c717-f612-4806-e98a-9fd447127397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "aF8cGxGQctlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a460925d6461448d8bd3980369690f55",
            "ed308cba93b842deab167bee9566b8ac",
            "c4a8bdb27f544eb7bf5e793c23ac6f03",
            "55c9d9a6248d4661b0da8a8e5381461e",
            "3e99ff2cfe50464eb00e76c5f6449e85",
            "196e6d477c3149a7bcbe426963360d72",
            "cdc256893db2447097cc668dc039f950",
            "7dfa823ab508453f944e8d1685c3bfca",
            "d28ba3f63f0c47aeba1044b4fe6b8d05",
            "da2a1e9a9d9c458e85c4e37bf92d8b3b",
            "19594b85244d427782c53ce6afd51e77"
          ]
        },
        "id": "j7Rp7lVrcvB2",
        "outputId": "075d8b45-aed0-404a-f7b4-6e4bdbf1b26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/18827 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a460925d6461448d8bd3980369690f55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT3-4FItcwu3",
        "outputId": "5c19a4cd-8f5d-4501-f5e8-5fdc3d814a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 18826310\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRl1gIKPcySF",
        "outputId": "50fbd34e-2d3f-441f-cf93-9576d5013e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 18826310\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_train = tokenized_dataset[\"train\"]"
      ],
      "metadata": {
        "id": "dv3YCuqoc0N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "c5cfjEuCc3p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Model"
      ],
      "metadata": {
        "id": "QkVJYXbHc4te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2Model.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "50b347481a9241dcb5a7c2143b550b7e",
            "a8e1b2737ebb4b2f8b020ae37fdfb18f",
            "68c9ed9957f441e3b033e7405b2228c7",
            "de4fc6a2eb0149909be433da37234802",
            "3f6822995fdb48059370658a05e7a75e",
            "bba3e532ae1f4395bb381087b64d524f",
            "f0c1b2df436840b1aa39293221c729d9",
            "1f3b57745d5f40d588e9ade87f3c17d3",
            "22b8c7bdcd224fc1b2007cc35ceca352",
            "cce6c131c9414d48af5a02570186de1a",
            "2b40f5ed303f41c6b60ab0941ef7a691"
          ]
        },
        "id": "tN2ShYy2c6UB",
        "outputId": "f49a1e03-11e8-4978-da99-4d04c5ad5efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50b347481a9241dcb5a7c2143b550b7e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "GgIrkppuc8Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(output_dir=\"model_checkpoints\")"
      ],
      "metadata": {
        "id": "J2JddFz9c9tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: See how to evaluate the model"
      ],
      "metadata": {
        "id": "1yPxpWKPc_QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "awfeNFNGdCtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset_train\n",
        ")"
      ],
      "metadata": {
        "id": "rUn-JUfndESu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "1jQMmH0PdFtY",
        "outputId": "1c866f2e-0f3c-4d71-e092-d96499159b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `GPT2Model.forward` and have been ignored: text. If text are not expected by `GPT2Model.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 18826310\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7059867\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1502\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1505\u001b[0m         )\n\u001b[1;32m   1506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2516\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2517\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2518\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2519\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2520\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                 )\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the 3rd or the 4th error in a row, so now I'm going to go with PyTorch fine-tuning approach. (https://stackoverflow.com/questions/72604790/how-to-train-gpt2-with-huggingface-trainer)"
      ],
      "metadata": {
        "id": "79ScHAwXSXCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch fine-tuning"
      ],
      "metadata": {
        "id": "2qq-eoSoRNjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "7EVkOmorRQvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # attempt to not use the GPU"
      ],
      "metadata": {
        "id": "yhf8LzNNRSIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From https://huggingface.co/docs/datasets/nlp_load:"
      ],
      "metadata": {
        "id": "od1UBdBRRV0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "sLue-SlHRW1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIRECTORY = \"dataset/txt_pruned\""
      ],
      "metadata": {
        "id": "Z4E49II9RYTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"text\", data_dir=DATASET_DIRECTORY)"
      ],
      "metadata": {
        "id": "e3w4KdLTRZZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "xpb6BQRWRbka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][10]"
      ],
      "metadata": {
        "id": "62Ism5zZRbzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "YmwUnXJbRc9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "eZFVeHlVReR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '<|pad|>'}) # added so that I don't get an error when tokenizing"
      ],
      "metadata": {
        "id": "Vnm_NZq7RhOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "IiiIaqaBRiSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "QoIqwPRARjYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "Ish0KTn3RkkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[\"train\"]"
      ],
      "metadata": {
        "id": "YSDMmZnPRlrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_train = tokenized_dataset[\"train\"]"
      ],
      "metadata": {
        "id": "pCX5QaHrRm7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's post-process the dataset:"
      ],
      "metadata": {
        "id": "L47LTYLARyA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_train = tokenized_dataset_train.remove_columns([\"text\"])"
      ],
      "metadata": {
        "id": "fR-qgay8R0Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_train"
      ],
      "metadata": {
        "id": "dwkx9SmIR1Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_train.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "53AKzGXwR2hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a DataLoader:"
      ],
      "metadata": {
        "id": "rv5WyzzeR3mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "atJ009qlR870"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(tokenized_dataset_train, shuffle=True, batch_size=1)"
      ],
      "metadata": {
        "id": "-fZAMdXdR-fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Model"
      ],
      "metadata": {
        "id": "bhXvTw8BR_l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2Model.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "XCg8lS81SAm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "Cow8sv1LSBrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "id": "f3qJp5ojSCza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "odl20l17SD7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler"
      ],
      "metadata": {
        "id": "uqK1zQ5BSE_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "doJKlOofSGFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "VqrhxsSySHTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\" # hardcoding cpu since I want it to run on the CPU, so I don't get out of memory errors\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "JqGYnFzqSIY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write the training loop:"
      ],
      "metadata": {
        "id": "FKiffm-sSLtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "iUMk8RcLSJ0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "7ng9hiqCSNL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm giving up on this approach as well, as it has given me many errors. (Note: I tested it locally, so there's no output here)"
      ],
      "metadata": {
        "id": "9PhrHSM1SOYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch fine-tuning #2"
      ],
      "metadata": {
        "id": "PISfR9OlcRiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Jupyter notebook is based on [this Jupyter notebook](https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing#scrollTo=U_XJVIetKN-h)."
      ],
      "metadata": {
        "id": "0MV4UI2nAjUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first define the dataset:"
      ],
      "metadata": {
        "id": "Cr_kns5bAmPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KbV27YXpAPmV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from transformers import GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset_dir, max_length=768):\n",
        "        # stores each line of the movie script file as a separate sequence\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.max_length = max_length\n",
        "\n",
        "        genre_subfolders = [subfolder_name for subfolder_name in os.listdir(dataset_dir)]\n",
        "        self.genre_subfolders = genre_subfolders\n",
        "        \n",
        "        # indicies used to load movie lines on demand (otherwise 25 GB of RAM is not enough)\n",
        "        self.genre_subfolder_index = 0\n",
        "        self.movie_script_in_genre_subfolder_index = 0\n",
        "        self.text_line_in_movie_script_index = 0\n",
        "\n",
        "        # stores the total number of movie lines across all movie scripts\n",
        "        self.total_number_of_movie_lines = 0\n",
        "    \n",
        "        current_cumulative_number_of_movie_lines = 0\n",
        "        # a dictionary that stores \"global\" movie line indices ranges (across all genres and all movie scripts)\n",
        "        self.genre_movie_script_pairs_global_end_index = {}\n",
        "        \n",
        "        for genre_subfolder in self.genre_subfolders:\n",
        "            genre_subfolder_path = self.dataset_dir + \"/\" + genre_subfolder\n",
        "            txt_files_names = [txt_file_name for txt_file_name in os.listdir(genre_subfolder_path)]\n",
        "            \n",
        "            for txt_file_name in txt_files_names:\n",
        "                path_to_movie_script = genre_subfolder_path + \"/\" + txt_file_name\n",
        "                with open(path_to_movie_script) as movie_script_file:\n",
        "                    movie_script_all_lines = movie_script_file.readlines()\n",
        "                    \n",
        "                    genre_movie_script_pair = str(genre_subfolder) + \"/\" + str(txt_file_name)\n",
        "                    self.genre_movie_script_pairs_global_end_index[current_cumulative_number_of_movie_lines + len(movie_script_all_lines)] = genre_movie_script_pair\n",
        "                    \n",
        "                    self.total_number_of_movie_lines += len(movie_script_all_lines)\n",
        "                    current_cumulative_number_of_movie_lines = current_cumulative_number_of_movie_lines + len(movie_script_all_lines)\n",
        "        \n",
        "        # prints for debugging purposes\n",
        "        #for global_end_index, genre_movie_script_pair in self.genre_movie_script_pairs_global_end_index.items():\n",
        "            #print(str(global_end_index) + \": \" + str(genre_movie_script_pair))\n",
        "            \n",
        "    def __len__(self):\n",
        "        return self.total_number_of_movie_lines\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        target_genre_movie_script_pair = None\n",
        "        previous_global_end_index = None\n",
        "        trail_global_end_index = 0 # stores the global end index of the previous genre movie script pair\n",
        "        \n",
        "        for global_end_index, genre_movie_script_pair in self.genre_movie_script_pairs_global_end_index.items():\n",
        "            if (idx < global_end_index):\n",
        "                target_genre_movie_script_pair = genre_movie_script_pair\n",
        "                previous_global_end_index = trail_global_end_index\n",
        "                break\n",
        "            trail_global_end_index = global_end_index\n",
        "        \n",
        "        path_to_target_movie_script = self.dataset_dir + \"/\" + target_genre_movie_script_pair\n",
        "        # prints for debugging purposes\n",
        "        #print(\"path_to_target_movie_script:\")\n",
        "        #print(path_to_target_movie_script)\n",
        "        target_movie_script_line_index = idx - previous_global_end_index - 1\n",
        "        target_movie_script_line = None\n",
        "        with open(path_to_target_movie_script, \"r\") as movie_script_file:\n",
        "            movie_script_file_all_lines = movie_script_file.readlines()\n",
        "            target_movie_script_line = movie_script_file_all_lines[target_movie_script_line_index]\n",
        "        \n",
        "        # prints for debugging purposes\n",
        "        #print(\"target_movie_script_line_index:\")\n",
        "        #print(target_movie_script_line_index)\n",
        "        #print(\"target_movie_script_line:\")\n",
        "        #print(target_movie_script_line)\n",
        "        encoded_movie_script_line = self.tokenizer(target_movie_script_line, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
        "        return torch.tensor(encoded_movie_script_line['input_ids']), torch.tensor(encoded_movie_script_line['attention_mask'])"
      ],
      "metadata": {
        "id": "G4pqeRLPAqfo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let me mount my Google Drive:"
      ],
      "metadata": {
        "id": "kr3jnaTsBqfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9w3l2zxBBJG",
        "outputId": "34635456-d2da-45be-8bdc-7e1026728b1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIRECTORY = \"/content/drive/MyDrive/Movie Script Generator/dataset/txt_preprocessed_v2\""
      ],
      "metadata": {
        "id": "cUi2twcvBtR8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write the data loader code and split the dataset into **train** and **val** subsets:"
      ],
      "metadata": {
        "id": "M_ri14uhCOBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "J2EVatXgCOnH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GPT2Dataset(DATASET_DIRECTORY, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "8069f2efbc8b4589935db063e602d366",
            "368443be0be84b27a3cf85be02c88924",
            "2e2551de9f0345e68ded3f58b446968e",
            "e49524a567c140deb8d0a9fbed74ead7",
            "37bd8284ddea48f69d44c7c7400e8c03",
            "9cad24cca1f041d282daaf217efb8732",
            "ae38246c25d444b9943bccfc21b32131",
            "e51a5f51cc3c4e508940bcd8311b81fc",
            "d2ceac7719e84a749648fbbd8dc12c35",
            "dec79a5de8d54c239bfc297b7a07b312",
            "aacda671b11f49cbaf88f44e58e3d9e4",
            "3322698af0314def94acff41262e27ef",
            "e7d9e8485f5e4cec82916cac4ea90ba2",
            "01038cedc4f64ce28fc837a74dd7b6dd",
            "bd2baf1e29ba41848f0b4d22a35f0b84",
            "b319b9976ba94a41b287eb2d25f10d68",
            "7814101e19b646bfb7427cfdc014bb76",
            "c5198aa9122641ac93566d2286f24e23",
            "44c2f9ad9c0141e7926a894d46ab8660",
            "b0c3159e563541c7806120ef8bf945eb",
            "d622320201bd4191b47441bbda903cde",
            "c2b5e2e76ebb43b889929c5f72d80646",
            "3905c09c9f2e45c68ebecc2c670989c2",
            "215d2c56a8ea418c9a52f1bf8e1c445e",
            "d13a18f929c443c892acfd2262eeae6a",
            "ed8cfaad3d804b598aa08f32e0007632",
            "59561f4704244775b9588a31f59ceeda",
            "ac5f67c5f6d44a1cb822307a99b1b4d5",
            "f0c3bbd2dda64ba596b1398d8b41a6d4",
            "ab661944b7ca487db619d5c146a38db5",
            "9c7d13118b9849029a3556cd4a2d5407",
            "44337b26ea1843f6bd3e9d2934ccc07e",
            "99d3b2039bcc4a8baf93f769a2bb6c26"
          ]
        },
        "id": "17EvZLODCUIa",
        "outputId": "d16e4dde-1a29-4d94-9f85-c7da395d57ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8069f2efbc8b4589935db063e602d366"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3322698af0314def94acff41262e27ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3905c09c9f2e45c68ebecc2c670989c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93,004 training samples\n",
            "10,334 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "oJBwbN-HYPp9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8"
      ],
      "metadata": {
        "id": "l_pWH84hDHv3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "jX55gq1zCrEg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning code"
      ],
      "metadata": {
        "id": "IUiAmFPpC3JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Config, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "0U35AAXOYSPi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7y6ZkF7YU2i",
        "outputId": "4649aa65-b220-4d5a-ba1d-74780609ce91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "#seed_val = 42\n",
        "\n",
        "#random.seed(seed_val)\n",
        "#np.random.seed(seed_val)\n",
        "#torch.manual_seed(seed_val)\n",
        "#torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "0ZHrhZDRCvFi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d602d44f95c64f4b85ccfbc56a81aa7c",
            "90847868ddb24c29989499c8c1003c5c",
            "128d056cb2c244d8848459da3ed32102",
            "8e4f2b8033c74f45a810fb5837ba3731",
            "6b4fa79ddb7444f192a81bea3ba54230",
            "fbfffa4f583d4365819790ddf0466044",
            "7c83471beec14d378954c30861f36059",
            "4c1aea51401e48e9b0e2d142837c6514",
            "e1617563e95f421cb0f54497e7316644",
            "a1d68ff22fc8465c8c887cf68e7c110d",
            "4b3a56a86054444380a6218d9b4197f8"
          ]
        },
        "outputId": "8c6e3180-8c1f-4d57-8332-e1c43c27a152"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d602d44f95c64f4b85ccfbc56a81aa7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "metadata": {
        "id": "h1SA9h0FCyzO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "5ZB7EmDBYXlq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "metadata": {
        "id": "sHvCHamUDJkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f354b4-c005-42d0-bee1-43eed8f1293f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "Rm3UpMkPDMgm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import random"
      ],
      "metadata": {
        "id": "H52AaX3iYbCR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "eJ285nO7DOTh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    #bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "id": "2lFPgzJADRbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Fine-Tuned Model"
      ],
      "metadata": {
        "id": "2J4nwwuxYfa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/Movie Script Generator/model_v2_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "metadata": {
        "id": "-t203rqyYeOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9818f833-439c-48c7-da37-2c05090b98db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/Movie Script Generator/model_v2_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Movie Script Generator/model_v2_save/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Movie Script Generator/model_v2_save/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Movie Script Generator/model_v2_save/vocab.json',\n",
              " '/content/drive/MyDrive/Movie Script Generator/model_v2_save/merges.txt',\n",
              " '/content/drive/MyDrive/Movie Script Generator/model_v2_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Fine-Tuned Model"
      ],
      "metadata": {
        "id": "hwFBHeKWDloi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.from_pretrained('/content/drive/MyDrive/Movie Script Generator/model_v2_save/')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "8PXQGmoH0Xey"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Text"
      ],
      "metadata": {
        "id": "T8H-G7mOEI_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below generates movie script lines based on genre prompts:"
      ],
      "metadata": {
        "id": "IOZOCF0PBhWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"COMEDY |\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoNnIfstECdw",
        "outputId": "6a72fa52-482c-4f68-98b9-7f3d2e8aebc6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9858, 1961,   56,  930]], device='cuda:0')\n",
            "0: COMEDY | <b> </b><b> INT. GROCER'S OFFICE - DAY </b><b> </b> There's a sign that says \"Office Space For Rent\". The place is in dire need of rent. <b> </b><b> </b><b> INT. LIVING ROOM - DAY </b><b> </b> The place is empty, only a few half-open bottles in one corner. Freddy's photo hangs on a wall. Next to it, the phone rings and rings. Freddy answers it. He smiles. <b> </b><b> FREDDY </b> Hello. <b> </b><b> KAREN </b> Is this you? <b> </b><b> FREDDY </b> It's me. I need an advance. <b> </b><b> CUT TO: </b><b> </b> Blade's footage of Karen screaming in agony. <b> </b><b> EXT. A DITCH - DAY </b><b> </b> Karen swims down the narrow drain. She passes an old ladder, and climbs on, looking around frantically for a way to get away. We see her POV through the crack. <b> </b><b> </b><b> INT. GROCER'S OFFICE - DAY </b><b> </b> Freddy is dialing a number on a phone. He holds up his hands. <b> </b><b> FREDDY (O.S.) </b> Karen, this is Karen Kinsella. <b> </b><b> EXT. MAIN HOUSE - DAY </b><b> </b> Karen enters the main house, a lawn mower in the backyard. It's almost completely bare -- except for a single light at the end of each door. <b> </b> It's the third or fourth floor of a small lower-middle class house. At this moment, the house is silent. Karen climbs into the back of an old Dodge Caravan and speeds off. <b> </b><b> </b><b> EXT. FREDDY'S APARTMENT BUILDING - DAY </b><b> </b> Karen drives out of the garage, away from the rent. <b> </b><b> </b><b> INT. A SHED - DAY </b><b> </b> Freddy is sitting in his bed as Karen enters from the other side. He's wearing his suit, but it's not Karen's apartment -- it's a tiny bedroom from the ground up. He picks up a bottle of champagne. <b> </b><b> FREDDY (V.O.) </b> So it's spring now, but spring has come to my senses. I can feel it. <b> </b> He picks up a glass of champagne and downs it a few more. We see his POV through the crack. <b> </b> He looks about, and the camera takes the focus back. <b> </b> He snaps out of his captions and focuses on Karen. She's now sitting on the end of a bench in the middle of the room. COMEDY | <b> </b><b> FREDDY (V.O.) </b> And the next morning, the vampire called to me and asked to fuck me for it. And like that, I've known it for ages, and even if the vampire turned me into a human, I would never leave Dana. <b> </b> Karen\n",
            "\n",
            "\n",
            "1: COMEDY | <b> EXT. STREET OUTSIDE DOG BUBBLE - CONTINUOUS </b> The red-and-blue police car cruises along with the limo. It's followed by a police caravan, followed by a caravan of other police vehicles. <b> INT. RAY'S BUGLE - CONTINUOUS </b> The red and blue police cars are parked a few yards apart. Ray is leaning against one of the cars. Ray's hands are just beneath the leather drapes over his shoulder. He is watching the house. <b> RAY </b> That's it? (beat) Yeah. It's over. <b> EXT. STREET - CONTINUOUS </b> The limo, with the police escort, pulls up behind and the car zooms through the trees. <b> INT. RAY'S BUGLE - CONTINUOUS </b> Ray is at the wheel, with his arms on the dashboard. He looks around the car. He can't see very far ahead, but he is just a few feet behind as he slows down to a crawl. He looks back at the house. <b> CLOSE-UP - CAR DOOR </b> open. Ray is watching the house from the window. <b> EXT. RAY'S BUGLE - CONTINUOUS </b> The limo stops at the top of a dune. As he starts toward it, a spotlight falls on it. Ray looks up at it, and then down at the lawn. He looks in. The house is still lit with the same security lights of earlier. He looks in. The lawn is empty. Ray looks at the house, then down at the lawn. He looks back at the house. He looks at the house, then at the lawn. Ray looks at the house, then back at the driveway. He looks at the house again. He looks at the house, then at the house. He looks in. No one is there. Ray looks back at the house, then back at the house. He looks at the house again. He looks in. He looks at the house again. He looks at the house. And Ray stares at the house. And then Ray closes his eyes. He looks at the house. The house. Ray reaches down into his pocket and takes out a small metal box from his pocket and opens it. He starts to pick it up. <b> EXT. DOG BUBBLE - CONTINUOUS </b> The limo stops outside the house. Ray looks around. No one is there. He gets a look at COMEDY | the house, then closes the door behind him. A few moments later, the limo pulls out. Ray walks around the car, looking around the front of the house. Ray looks at the back door. It seems to be locked. Ray picks up a small plastic box and opens it. No one is there. He opens the box. It's full of pictures. Pictures. <b> INSERT - PICTURES </b> Different shots. Shots of people. A man in his mid-fifties. A small boy in a bathrobe. <b> INSERT - PICTURES </b> Different shots of him. A man in a wheelchair walking down the street. A man at the end of the sidewalk, leaning against a tree. And a couple more pictures of the same people. Ray stares at the back of the house. The hallway. <b> EXT. DOG HOUSE - CONTINUOUS </b> Ray picks up the plastic box and walks over to the front door. There are a dozen or so people inside\n",
            "\n",
            "\n",
            "2: COMEDY | </b> <b> </b> <b> </b> <b> </b> <b> 49. </b> <b> CONTINUED: </b> <b> TONY </b> Are we gonna let this guy go? <b> MICHAEL </b> Yeah. Sure. Of course. I'm not going to let him go. I just want you to know I don't think he'd approve of doing this. We should just get on with the business. He walks out of the restaurant. <b> TNT. CHANGING ROOM </b> TONY is still walking outside. MICHAEL follows behind, and sits down. They wait for a few beats. <b> TONY </b> I want you to keep this up. They sit in silence for a beat. <b> TONY (CONT'D) </b> I'm not sure the big man is the type of guy who'd do something like that and make a deal. <b> MICHAEL </b> I hope so. I want you to keep this up and make a deal with me. <b> TONY </b> For what? <b> MICHAEL </b> Your life. What do you mean? It's a simple deal. <b> TONY </b> This is your life. This is the way it works. <b> MICHAEL </b> I don't really understand. <b> TONY </b> Well, I'd love to keep up your time. What kind of deal? <b> MICHAEL </b> A simple one. <b> </b> <b> </b> <b> </b> <b> </b> <b> 49. </b> <b> CONTINUED: </b> <b> TONY </b> A simple deal, huh? MICHAEL looks at him, trying to think of an answer. <b> MICHAEL </b> Are you all right? TONY's head turns. <b> TONY </b> I don't think so, boss. I mean, I just want to think of something, okay? A beat. <b> TONY (CONT'D) </b> I have a question for you, boss. You have to do what you want. <b> MICHAEL </b> I do. I want to be able to be a manager. I want to be a boss. TONY looks at him and gives him a long look. <b> TONY </b> What's a boss like? He doesn't know how to be so cocky, and he keeps his distance, but it might suit him. <b> MICHAEL </b> How do I make sure you get the job? The old boss doesn't answer. TONY's head moves, so he knows Michael will say no more. <b> TONY </b> So, what can you do for me, boss? We're done. They are silent for a beat. COMEDY | TONY shrugs. <b> TONY </b> I'm sorry you feel the same way. <b> MICHAEL </b> I know. <b> TONY </b> You have a problem with it? MICHAEL keeps his eyes on TONY. <b> </b> <b> </b> <b> </b> <b> </b> <b> 50. </b> <b> CONTINUED: </b> <b> MICHAEL </b> Yeah. It's okay, boss. <b> TONY </b> And it might\n",
            "\n",
            "\n",
            "3: COMEDY | They pull up. Rick looks over at Wendy. <b> RICK </b> How are you guys? Wendy shakes her head. <b> WENDY </b> They're not as big as she looks. I don't even know how to say these things. <b> WENDY </b> We are very lucky. Wendy looks at Rick. <b> WENDY </b> I didn't hear your voice. <b> WENDY </b> I heard it before. We will see what you have to do. <b> INT. RICK'S APARTMENT - DAY </b> Rick opens his door and walks into the apartment. <b> INT. BATHROOM - DAY </b> Rick walks into the bathroom. A few seconds later, he sees Wendy coming in and the door is ajar. He walks towards the sink and quickly turns on the water. His face is splashed with shaving cream. Wendy comes down the stairs. <b> WENDY </b> Rick. What's wrong? <b> RICK </b> I just got in. Rick starts drying off. <b> WENDY </b> Oh, that was just great, did you get something? I told you I think it's water. <b> RICK </b> Oh. <b> WENDY </b> Really? What do you do? She walks in from the kitchen. She is very friendly, and genuinely cute, and clearly not into Rick's pants anymore. <b> WENDY </b> I was just going to get a beer. <b> RICK </b> Oh, I'm not a beer. I'm just into a few drinks. <b> WENDY </b> Well, do you really have a lot to drink? <b> RICK </b> No. I've got two things to deal with. <b> WENDY </b> What are you talking about? <b> RICK </b> That you might want to come out a while. <b> WENDY </b> Wait, this was before I went out on a date. <b> RICK </b> Why? <b> WENDY </b> I mean, it's just that, it doesn't seem that bad, when you say that. <b> RICK </b> I just mean, that was before we got married. Oh yeah. You mean... <b> WENDY </b> I mean, then you said you liked it, right, and then you walked away. <b> RICK </b> So, this is another time. She turns back to him. <b> WENDY </b> I'm sorry. <b> RICK </b> Why can't we go back to Vegas? <b> WENDY </b> I think we can keep the time. I don't care. <b> RICK COMEDY | </b> Because that might be a lot longer than we agreed. <b> WENDY </b> It doesn't matter. I like you. <b> RICK </b> Yes it does, Wendy. <b> WENDY </b> What? <b> RICK </b> And it's kind of annoying, that thing with the big fat fucking mole. <b> WENDY </b> No, you don't understand. I really mean it. You do and I will respect it. I do. <b> RICK </b> Do you want to go back to Vegas or wherever you want to go.\n",
            "\n",
            "\n",
            "4: COMEDY | He walks over to the table with a cup of coffee, which he takes. <b> WILSON </b> (raising his cup) I can't take that. I'm not going to the club to get on some show! He raises a glass of milk and a large can of beer. <b> SONDRA </b> (calling) Good afternoon. <b> WILSON </b> (raising glass) Is this your last day at the club? <b> SONDRA </b> (scared) It's a birthday party. <b> WILSON </b> But it's a birthday party, don't worry about it, I'm a little busy. I'll make the call in a minute. He pours the milk into two glasses. He leans down and pours her milk into the two glasses. She takes a sip, then she pours two glasses and then puts one in his cup. He drinks hers. Then he leans forward and takes one out. <b> WILSON </b> Here's to dinner. (pausing while drinking, then pours him more milk) There's nothing in the whole bag I'd like. (pausing, looking at her feet) What are you going to do now, sit down in the car, put my seat belt down like this? <b> SONDRA </b> (after a moment) What? No. I'm... I just wanted to... I don't know. Can I talk to you tonight? <b> WILSON </b> (reluctantly) Yeah, why not? What do you need? <b> SONDRA </b> (looking at him) I don't know what I need. <b> WILSON </b> Sure, why not. But... because if I don't, I'm going to find out where I live and I won't be able to go to church much later. (pausing, looking at her feet) I can't believe that. He pours two more glasses of milk into his cup. <b> SONDRA </b> (smiling) That was my last day at the office? <b> WILSON </b> Yeah, I guess I have a few problems. They drink their drinks. <b> WILSON </b> (continuing) I have a girlfriend. She's... she's... <b> SONDRA </b> (after a moment, seriously) Oh, my God, no, wait a minute. <b> WILSON </b> It was like a week ago. You know, I just didn't seem right... I used to have a new car. I have a wife... and two kids... <b> SONDRA </b> Oh, well... I'm sorry. I should have known. (pouring more milk) I'm really sorry, that was hard for you COMEDY | to say. It was just... to just... say, \"Sorry.\" (pausing, pouring two glasses of milk) I've had a pretty hard time, you know. I'm sorry. <b> WILSON </b> (a bit confused) Oh. Oh, that poor, poor thing. <b> SONDRA </b> You mean like me? <b> WILSON </b> Yeah, I mean, I know I've been pretty hard to tell, but... I know I've been really, really hard to tell. <b> SONDRA </b> I think that's very clever. Because I was so interested in my life that I was able to say... well\n",
            "\n",
            "\n",
            "5: COMEDY | </b> You're getting the fuck outta here. You're not supposed to get on vacation. The bus stops in the middle of the desert... A bus approaches, a woman and her children step out. The bus comes to a stop, their parents wave from the windows. <b>EXT. DESERT BUS </b> A long aisle of buses is lined up in front of a bunch of TV repair trucks and repair trucks. <b>INT. TV REPAIR TRUCK </b> The TV repair truck is a multi-leveled vehicle, a multi-leveled multi-vacant vehicle, with several repair trucks, one on each side. The entire crew is crammed in the back. Large motors are hooked up to three large mains and repair lights. Large motors go into a huge battery and drives around the truck, stopping to pick up some tools. A crane lifts off a mower. Large motors start up and the crane lifts off a long shelf of parts. Small motors pull a hydraulic press down from the ceiling to a large drill and drill. Large motors drive up to the ceiling and out of frame. <b>INT. TV REPAIR TRUCK </b> This is the big assembly line of repair equipment. Large motors drive up to the drill. <b> </b> <b> 14. </b> <b>EXT. DESERT BUS </b> The bus stops at a stop next to a shop with a big repair truck on top of it. A hand goes to help Large open the truck door. A woman steps out of the bus and leans on the roof. <b>EXT. TV REPAIR TRUCK </b> This is the main stage of the show. A huge section of the roof is open and Large stands in the open doorway to the shop. He begins to walk towards the shop with the crane. Suddenly a piece of glass breaks. Large looks up to see the entire crew standing there, smiling. Large notices. <b>INT. TV REPAIR TRUCK </b> Large raises his arms to the heavens. He takes out his camera and turns it on. An image appears in his camera. He points it at the audience. On the screen the two women begin to sing. Large smiles and takes a camera with him. The camera stays on Large. COMEDY | <b>INT. TV REPAIR TRUCK </b> The sound of the music continues through the truck. Large walks through the room. He takes a bunch of keys off a belt. <b>EXT. DESERT BUS </b> He walks over the dusty road and makes his way down the road. He gets into a wheel-less Toyota Crown moldering toolbox with a handlebar and a battery. He gets in, and turns out the ignition. He watches as the tires slowly begin to clank. He watches as they slowly shut down. He watches as the rear-view mirror starts to steam up from the heat. Large climbs in to get the car. <b>INT. TV REPAIR TRUCK </b> Large reaches into the front and takes out the battery. He reaches over and grabs a screwdriver. He hands the screwdriver to the driver and puts it to work. The truck's electric motor turns on and the drill bit rips into the wood and pieces drop onto the dirt. Large reaches into the glovebox. He finds a small toolbox. He pulls down the metal. With the drill bit in it, he starts pulling the metal away from the wheel-less car. Large takes out a section of a car hood and places it on the tool box. He begins opening the hood. He pulls down the hood and pulls\n",
            "\n",
            "\n",
            "6: COMEDY | </b> She stops and turns as the attendant enters. She says nothing. <b> </b> The camera follows, scanning, and we find that Stanley is now wearing his chewed-up suit. He is leaning over the edge of the bed as if he's been sleeping. He is smiling at the camera. <b> </b><b> TINA (CONT.) </b> Oh, that's so cool... <b> </b> The camera pulls back to reveal the sound of laughter. Stanley's eyes widen. He looks down at the sheets. He shrugs. <b> </b><b> STANLEY </b> Well? <b> </b><b> TINA </b> Well, I didn't want to get in your face, but you can bet, you're getting fat. <b> </b> Stanley continues laughing. <b> </b><b> TINA (CONT.) </b> You're disgusting to me. Look, you said you loved me... and now you're laughing all night. Why do I always see you laughing? <b> </b><b> STANLEY </b> Because I love you. <b> </b> He smiles to himself and stands up. <b> </b><b> STANLEY (CONT.) </b> Now, go ahead. You are not my type. I'll call you in the morning. <b> </b> The laughter stops and the camera pulls back, to reveal Rita seated at her vanity. She wears a small black dress with the words \"ROGUE RITZY\" on the front. <b> </b> The laughter is still in the background and we can see that Stanley's voice has been amplified. <b> </b><b> STANLEY (O.S.) </b> (Over the laughter) I mean it's not funny that a nice-looking, pretty guy like you should get married. <b> </b> She looks down at her dress. <b> </b><b> STANLEY (O.S.) (CONT.) </b> (Over the laughter) Hey, hey, hey, this is my wife and we're gonna have a baby. That's her. I think it's good for us... I think she's beautiful. <b> </b> Rita pulls up the dress and looks at herself in the mirror. <b> </b><b> RITA </b> Hi, how's everything goin'? I just wanted to say, thanks for the money. <b> </b> She wipes away her tears with her hand and turns from the mirror. <b> </b><b> RITA (CONT.) </b> What did you want with me? <b> </b><b> STANLEY </b> To give you something, Rita. You know, for my baby. And to have it back. So, uh... <b> </b> She takes some things off the rack and throws them on the dressing table. <b> </b><b> RITA </b> Come on! <b> </b> She turns and goes out. Stanley sits on the edge of the bed staring at the ceiling. COMEDY | <b> </b><b> STANLEY </b> Oh, shit. <b> </b> He sits up for a second, still watching the ceiling, and then starts to laugh. <b> </b><b> STANLEY (CONT.) </b> Listen, I love you. I love you, too. I love you.\n",
            "\n",
            "\n",
            "7: COMEDY | <b> MIRANDA </b> You did? I thought you said you did. <b> EMILY </b> I did, honey. <b> JIMMY </b> You did? Miranda shrugs, then leaves. Jimmy goes to a table and grabs his camera. <b> JIMMY </b> No, I'm just gonna get through this. I can't work on any of this without you guys on my side. I know it's crazy, but you don't know it's crazy. <b> MIRANDA </b> Jimmy, what about the guy? <b> JIMMY </b> I don't know what he's doing. Miranda looks at him and smiles. <b> MIRANDA </b> You didn't say anything about him? <b> JIMMY </b> No, baby. <b> MIRANDA </b> Then you're gonna start doing something else? <b> JIMMY </b> No, I'm not. <b> MIRANDA </b> Then we're gonna do something together? <b> JIMMY </b> Yeah, like what? <b> MIRANDA </b> I'm going on a bike ride. I'm gonna get married and have a kid. And I'm gonna be a doctor, and a lawyer. And I'm gonna be a lawyer. And I'm going to be a dad. You understand? <b> JIMMY </b> Yeah. <b> INT. JIMMY'S BEDROOM - A FEW MINUTES LATER </b> Jim and Miranda sleep. <b> JIMMY </b> I think you should stay with your family, honey. I don't know how you do, but you have a good friend. So, you come down, and... I mean, you always say you're proud of me, and, I think that's amazing. I think you do, too, honey. <b> MIRANDA </b> I really do. <b> JIMMY </b> Come down. <b> INT. TASKER HOUSE - NIGHT </b> In the living room, a family of forty is gathered. Doug, Doug, and Landon are sitting around, listening to the T.V. The family conversation seems less and less interesting. <b> DISSOLVE TO: </b> <b> INT. JIMMY'S BEDROOM - DAY </b> <b> JIMMY </b> (to himself) We can do it. But you have to get rid of him. You gotta do it fast. Remember? <b> DISSOLVE TO: </b> <b> INT. LIVING ROOM - MORNING </b> Jim and Miranda are sleeping. <b> JIMMY </b> (to Landon) You know, I really don't want to be a parent anymore. <b> DISSOLVE TO: </b> <b> EXT. JIMMY'S HOUSE - DAY </b> The morning sun is shining in the trees. COMEDY | <b> JIMMY (V.O.) </b> Now that I've got the time to tell you that, I have to get a good night's sleep. And you have a good night's sleep too. <b> DISSOLVE TO: </b> <b> INT. JIMMY'S BEDROOM - DAY </b> <b> JIMMY (V.O.) </b> As\n",
            "\n",
            "\n",
            "8: COMEDY | of that. It's not easy in the world, but it was better when I was eight years old when I started to think about my father, his illness, and the things he would do to me. I lived the life I wanted. <b> FRANK </b> Did he ever mention the fact that he married a Democrat? <b> DREW </b> Never! <b> JERRY </b> He's a real jerk on the inside, Frank. He's going to destroy you and your family if you let him destroy you. <b> FRANK </b> What's a Republican like him do? <b> JERRY </b> He's the ultimate liberal. He's all white trash, he's a puss. And he loves you, and it's a pity you don't come back. <b> FRANK </b> I love you too. I love you so much. <b> JERRY </b> I know. Maybe you don't know it. Maybe I don't even care. <b> FRANK </b> Then tell me, do you think I should call you Frank, because I want to be with you forever? <b> JERRY </b> That'd be nice. <b> FRANK </b> Fine, let's call you when I get home. <b> JERRY </b> If you don't, I'll just go and get it ready. <b> FRANK </b> You don't know what's good for me, do you? Besides I'm not sure. <b> JERRY </b> Maybe you'll call and say, \"I know, I'm home, Dad.\" I'll think about it. <b> FRANK </b> I guess that would be nice. <b> JERRY </b> What if, after eight years, you tell me that I shouldn't. And what would you do? <b> FRANK </b> Well, you know what, I wouldn't even do it, but... <b> JERRY </b> It would be stupid to ever call me again. <b> FRANK </b> I suppose so. <b> JERRY </b> Well, how many you need? <b> FRANK </b> Twenty. How much would I have left if the two of you had gone away? <b> JERRY </b> Thirty-seven and a half, aren't you? A couple of million? Frank doesn't answer. <b> JERRY (CONT'D) </b> Look at me, Frank. I didn't come along and just ended up stuck on the same side. <b> FRANK </b> Well, maybe you have other problems with it, Jerry. Don't you? <b> JERRY COMEDY | </b> Not really. <b> FRANK </b> Would you like to see it? <b> JERRY </b> Okay. <b> FRANK </b> Would you like to see it? <b> JERRY </b> Sure. <b> FRANK </b> Thank you. <b> JERRY </b> See ya. <b> FRANK </b> See ya. <b>EXT. RIVERSIDE - DAY </b> We see a car that drives through the beautiful countryside, through the lush trees, straight to the river. We see a pretty girl in a bikini. We see the driver of the car, DREW. <b> DREW </b> Good morning, young\n",
            "\n",
            "\n",
            "9: COMEDY | the edge, looking at the road -- and suddenly -- <b>ANGLE FROM STREET BELOW </b> A couple of cars turn left, right, left -- and make it onto the bridge. As the cars pass, the other cars make the same determination. They leap out of their cars, sprint for the bridge and leap over the side, onto the river. As they leap over the side, the river's edge is still water. They sprint down a side bank and leap over the lip, in pursuit. <b>EXT. OLD FORT BRIDGE </b> They climb over the edge of the water and continue down the hillside, looking up at the bridge above. <b>ANGLE ON BRIDGE </b> The cars continue to race back toward the bridge, toward the house. <b>EXT. OLD FORT BRIDGE POV </b> From their cars -- now we can see the house, with its low-slung windows. The two men are nowhere to be seen. But there's no sign of the man in the trenchcoat. They can still hear the crash of a car behind them, and they leap over the side -- <b>EXT. OLD FORT BRIDGE'S POV </b> -- where the convertible is still running, upside down, on the road, coming right for them. <b>ANGLE ON CARS </b> Driving in the opposite direction. The cars can see the road before them. And yet they're not moving. They're still following the car. <b> </b><b> 41. </b> <b>INT. CAR </b> The driver of the car hears the crash -- looks around. It's another man's car. And that's exactly what the two men are up against. They race back toward the house, but the convertible slows and the man in the trenchcoat is nowhere to be seen. When the car is over, he jumps off his car. He gets out, runs through the rain, looks to his left. The house has broken up. He goes over the side, into the trees. <b>EXT. OLD FORT BRIDGE VIEW </b> The road is still, and in the CROWDS OF THE ROAD, we can see the man and the car, racing toward them. <b>EXT. SOUND OF ROAD </b> They are still racing down a steep hilltop, side by side. The man in the trenchcoat appears at one point of the bridge, the cars at the other. We can see him, COMEDY | through the rain. They turn right and start up the hill, toward the bridge, racing toward them. <b>EXT. BRIDGE </b> He jumps off his car, sprints up the hill toward them. <b>EXT. ROAD </b> The convertible has a sudden hit -- the man in the trenchcoat has died. The other man's body is on the road, but no one else has come out of the brush. The convertible spins and flips, hits a ditch, and hits the curb, bouncing the man's body into the mud. <b>EXT. BRIDGE </b> They reach the bridge, and the car on the bridge above flies out over the hilltop, onto the river below. The man in the trenchcoat looks up at the bridge -- <b> </b><b> 42. </b> -- and gets to his feet, looking down. He looks over at the truck on the truck, where the driver is out, and says -- <b> MAN </b> Go on up! Hurry up!\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"COMEDY |\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxVKausFsRAB",
        "outputId": "2484d44b-122d-49a3-d0a4-67cc7f9ab8a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9858, 1961,   56,  930]], device='cuda:0')\n",
            "0: COMEDY | </b> I hate you, man. What does he say to you? <b> MR. SPOOK </b> He says he thinks you're... <b> CLIVE </b> A good one. But don't know why... (a beat) I know why. <b> MR. SPOOK </b> (after a beat) Is that right? <b> CLIVE </b> (smiles) I just don't... that. Mr. Sparkly gestures for her to put it in her hands. <b> MR. SPOOK </b> You'll help him to the door? <b> CLIVE </b> I don't know. <b> MR. SPOOK </b> Just then, something POUNDS on the door. <b> CLIVE </b> Who is it? <b> MR. SPOOK </b> (a beat) Man's inside. There's a beat. A knock. <b> CLIVE </b> Mr. Sparkly... <b> MR. SPOOK </b> (over his shoulder) Are you alright, Miss Vale? <b> CLIVE </b> Yes. <b> MR. SPOOK </b> Do you mind if I go inside? <b> CLIVE </b> Why don't you just wait outside? <b> MR. SPOOK </b> No, don't go. I can see you're upset. <b> CLIVE </b> Are you upset too? <b> MR. SPOOK </b> Yes, yes, I am. Now just just relax and I'll get out. <b> INT. ABANDONED METRO CITY LIBRARY - DAY </b> The door opens and a MAN steps into the corridor. He is followed by FLASH and a SECURITY CAMERA. <b> SECURITY CAMERA </b> (to camera) What happened? <b> FLASH </b> (to security guard) Watch him, if you see anything. Just let me see you come in. <b> SECURITY CAMERA </b> (to camera) Good. <b> FLASH </b> We need the cameras now, will you? <b> SECURITY CAMERA </b> Of course, why not? <b> FLASH </b> We need them on this door. <b> INT. ABANDONED METRO CITY LIBRARY - DAY </b> The Guard comes in, followed by Flash and the Technician. <b> SECURITY CAMERA </b> Okay, come in, Mr. Vale. Can you see me, please? <b> VALE </b> (stops, looks up from her desk) Um... I'm here, but I can't tell. Flash takes the camera and holds it against his temple. <b> FLASH </b> That's okay. <b> INT. ABANDONED METRO CITY LIBRARY - DAY </b> The Man goes into the room where the bodies are laid out. He finds them and turns back to the cameras. <b> SECURITY CAMERA COMEDY | </b> (to camera) Okay. All right, all right. Now just get him to the door. <b> FLASH </b> Ok. Here goes. <b> INT. ABANDONED METRO CITY LIBRARY - DAY </b> <b> SECURITY CAMERA </b> (beat) Alright, here he is. <b> INT. VALE'S APARTMENT - DAY </b> Vale has\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below should generate movie scripts, taking into account previous context:"
      ],
      "metadata": {
        "id": "fvDsMGjDAMWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "#prompt = \"<|startoftext|>\" # if I include this in the prompt, it generates garbage\n",
        "genre_name = \"COMEDY\"\n",
        "#prompt += \" \" + genre_name + \" | \"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  # debug prints\n",
        "  #print(\"sample_outputs:\")\n",
        "  #print(sample_outputs)\n",
        "  #print(\"sample_outputs[0]:\")\n",
        "  #print(sample_outputs[0])\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  try:\n",
        "    prompt = genre_name + sample_output_decoded_parts[2]\n",
        "  except: # on this rare occasion, GPT-2 didn't generate the second genre_name in the middle of the generated sequence\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_after_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[half_sample_output_decoded_tokens_length:sample_output_decoded_tokens_length]:\n",
        "      prompt_after_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints\n",
        "    #print(\"prompt_after_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_after_genre_name_and_vertical_line)\n",
        "    prompt = genre_name + \" | \" + prompt_after_genre_name_and_vertical_line\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "-Hb_ZxEcESLA",
        "outputId": "84144819-8f78-42b5-9787-b3799351ae67"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | urns are lit up. The house is empty except for two chairs with an antique piano, a pair of comfortable chairs and a small window. JACOB (v.o.) It occurred to me that I was having my last full word, since I couldn't begin to recall who I was. The light starts to come on. JACOB (v.o.) Then I woke up and there was a huge cloudburst of dust. I guess it wasn't just a cloudburst, but an amazing deluge. It was about a thousand gallons of pure oxygen. I had no clue who I was... and I had no idea who I was. We are close on JACOB. We see him for the first time. <b> JACOB (V.0.) </b> It's hard to tell whether I'm having an hallucination or just a hallucination. We are close on his eyes. <b> JACOB (V.O.) </b> If everything's all right, it might help to ask who I am. You see what I'm hallucinating about, on the other hand, have no idea. I can't tell. It's a huge, staggering, staggering dizzying sensation. <b> EXT. HAVENHURST - LATER </b> JACOB is sitting next to an open champagne bottle. He holds the glass up to a starlit, shimmering world. <b> JACOB </b> A person's hallucination can be a very real experience. That's the reason I'm here. To tell you about it. JEZZIE is standing next to him. She hands him his champagne glass. JACOB (cont'd) I have never been much good with people. But as you have probably noticed, I am very much alive. He gestures to the city behind them. <b> JACOB </b> What's the capital of New York City? <b> JEZZIE </b> Central Park, New York City. <b> JACOB </b> Really? <b> JEZZIE </b> It's the world's most active park. <b> JACOB </b> Really. Isn't this amazing? What's the capital of New York City? <b> JEZZIE </b> New York City. <b> JACOB </b> Really? <b> JEZZIE </b> Yes. <b> JACOB </b> Do you believe it? <b> JEZZIE </b> I think so. JACOB beams and takes a huge swig of champagne. <b> JACOB </b> A lot of people are. You wouldn't have to be so foolish to tell me that. <b> JEZZIE </b> I'm not a foolish man to do so. I'm not. <b> JACOB </b> Yeah? How about the man who's always being me is the man I \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | am? And this woman I'm dying to marry? What is her name? A pretty middle aged woman in her forties. <b> JEZZIE </b> Elaine. <b> JACOB </b> Do you love her? <b> JEZZIE </b> Yes, but she's not even married. That's an important moment for me. <b> JACOB </b> What do you know about it? <b> JEZZIE </b> I just know, this is a very complicated world to me. <b> JACOB </b> I don't know what you mean. She's very young and you're a nice person and it's very interesting that you're married and together I'm very much alive. And I'll tell you why, because I'm attracted to you. In a way she's a love of my life. (Almost tenderly) Are we on the same page? <b> JEZZIE </b> Yes. <b> JACOB </b> And is it true about you? <b> JEZZIE </b> Yes, I'm sure it is. JACOB studies her a second. <b> JACOB </b> Are you happy? <b> JEZZIE </b> Yes, I am, but I'm not happy. <b> JACOB </b> You can't be happy? <b> JEZZIE </b> Yes. <b> JACOB </b> Why? <b> JEZZIE </b> I don't know what to think. <b> JACOB </b> Why? <b> JEZZIE </b> Because I can't believe it. She's so beautiful, the way she dresses. She's so beautiful, the way she holds herself up, the way she looks on the floor, the way she's dressed, that's the only thing I can think of. She has energy, sensibility, wisdom. I don't know what's real, what's beautiful, what's not. But I can feel it when I'm trying to love her. <b> JACOB </b> Are you happy? <b> JEZZIE </b> Yes, I am, I think. <b> JACOB </b> Have you been in love with anyone recently? <b> JEZZIE </b> I don't think so. I mean really lately. <b> JACOB </b> Have you ever been alone? <b> JEZZIE </b> No. <b> JACOB </b> Have you been alone with anyone recently? <b> JEZZIE </b> No, I don't think so. I'm married. I'm only going to be single for a year. I have never been alone with anyone for a year. <b> JACOB </b> Why? <b> JEZZIE </b> Because I can't think of anything else to say. <b> JACOB </b> Why? She doesn't answer for a moment. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | <b> JACOB </b> Why? <b> JEZZIE </b> Because you're so beautiful. She's so good to me. I'm not really her lover. JACOB stares at her a long time. She still doesn't answer. <b> JACOB </b> Are you sure? <b> JEZZIE </b> Yes. <b> JACOB </b> So, what does it say? <b> JEZZIE </b> I don't know. <b> JACOB </b> What do you mean? <b> JEZZIE </b> That it's too much. <b> JACOB </b> Oh, great. That's great. <b> JEZZIE </b> Yeah. <b> JACOB </b> Great. Okay. Let's go see a movie. <b> JEZZIE </b> Yeah? <b> JACOB </b> Yeah. <b> JEZZIE </b> Can we see it? <b> JACOB </b> Yeah. <b> JEZZIE </b> Why? <b> JACOB </b> You mean, what? <b> JEZZIE </b> You mean, tell me. I want to see it. <b> JACOB </b> Yes. Of course. Okay. <b> JEZZIE </b> Wait a second. What does it say? <b> JACOB </b> (very quiet) It says, \"Please tell me I'm beautiful.\" <b> JEZZIE </b> Are you happy? <b> JACOB </b> Yes. Happy, yes. Happy. Happy. <b> JEZZIE </b> Say, is that a pretty thing? <b> JACOB </b> Yes. Say, are you happy? JEZZIE looks at the door, then at the lights. <b> JACOB </b> Oh, great, great. Okay. Well, what about me? Is that what you're trying to say? <b> JEZZIE </b> No. Of course not. I'm not sure you are? <b> JACOB </b> Yes. <b> JEZZIE </b> What's wrong with me? <b> JACOB </b> Yes. Say, is that what you're trying to say? <b> JEZZIE </b> Yes. Yes. <b> JACOB </b> If this is a really beautiful thing, it'll be love at once. It'll be love at once. Now, what's the difference between love and hate? You'll never be perfect. JEZZIE stares at him. <b> JACOB </b> Well, I don't know if that's what it would mean. Probably not. <b> JEZZIE </b> I know you'd be so happy to have someone you could date. <b> JACOB </b> I'm not sure that is possible. <b> JEZZIE </b> Can we go see it tomorrow? <b> JACOB </b> Sure. <b> JEZZIE </b> Oh, right. Great. Bring me the cake. <b> JACOB </b> Yes, of course. I have to get going. JEZZIE leaves the living room and heads for the bathroom. JACOB follows her. <b> INT\n",
            "COMEDY | you happy? JEZZIE looks at the door, then at the lights. <b> JACOB </b> Oh, great, great. Okay. Well, what about me? Is that what you're trying to say? <b> JEZZIE </b> No. Of course not. I'm not sure you are? <b> JACOB </b> Yes. <b> JEZZIE </b> What's wrong with me? <b> JACOB </b> Yes. Say, is that what you're trying to say? <b> JEZZIE </b> Yes. Yes. <b> JACOB </b> If this is a really beautiful thing, it'll be love at once. It'll be love at once. Now, what's the difference between love and hate? You'll never be perfect. JEZZIE stares at him. <b> JACOB </b> Well, I don't know if that's what it would mean. Probably not. <b> JEZZIE </b> I know you'd be so happy to have someone you could date. <b> JACOB </b> I'm not sure that is possible. <b> JEZZIE </b> Can we go see it tomorrow? <b> JACOB </b> Sure. <b> JEZZIE </b> Oh, right. Great. Bring me the cake. <b> JACOB </b> Yes, of course. I have to get going. JEZZIE leaves the living room and heads for the bathroom. JACOB follows her. <b> INT  \n",
            "COMEDY | hate? You'll never be perfect. JEZZIE stares at him. <b> JACOB </b> Well, I don't know if that's what it would mean. Probably not. <b> JEZZIE </b> I know you'd be so happy to have someone you could date. <b> JACOB </b> I'm not sure that is possible. <b> JEZZIE </b> Can we go see it tomorrow? <b> JACOB </b> Sure. <b> JEZZIE </b> Oh, right. Great. Bring me the cake. <b> JACOB </b> Yes, of course. I have to get going. JEZZIE leaves the living room and heads for the bathroom. JACOB follows her. <b> INT   \n",
            "COMEDY | JEZZIE </b> Can we go see it tomorrow? <b> JACOB </b> Sure. <b> JEZZIE </b> Oh, right. Great. Bring me the cake. <b> JACOB </b> Yes, of course. I have to get going. JEZZIE leaves the living room and heads for the bathroom. JACOB follows her. <b> INT    \n",
            "COMEDY | Yes, of course. I have to get going. JEZZIE leaves the living room and heads for the bathroom. JACOB follows her. <b> INT     \n",
            "COMEDY | and heads for the bathroom. JACOB follows her. <b> INT      \n",
            "COMEDY | her. <b> INT       \n",
            "COMEDY |       \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e9ea6286370e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# print the last part of the last generated line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code doesn't produce good results most of the time (in 7/10 runs it produced garbage)."
      ],
      "metadata": {
        "id": "Kulp6JzxxDFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try generating a movie script with a prompt that looks as follows:"
      ],
      "metadata": {
        "id": "eS9G1eD3vMo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**half of the generated line | genre name**"
      ],
      "metadata": {
        "id": "qPlSaMj9vPm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "genre_name = \"COMEDY\"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints below\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints below\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded:\")\n",
        "  #print(sample_output_decoded)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  prompt = sample_output_decoded_parts[1][2:] + \" \" + genre_name + \" | \" # the sample_output_decoded_parts[1][2:] gets rid\n",
        "                                                                         # of the \" | \"\n",
        "\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  \n",
        "  if (len(sample_output_decoded_parts) == 2): # the midway genre tag wasn't generated\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_before_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[:half_sample_output_decoded_tokens_length]:\n",
        "      prompt_before_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints below\n",
        "    #print(\"prompt_before_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_before_genre_name_and_vertical_line)\n",
        "    if (prompt_before_genre_name_and_vertical_line != genre_name + \" | \"):\n",
        "      prompt = prompt_before_genre_name_and_vertical_line + genre_name + \" | \" # avoids duplicating the genre tag and the vertical line\n",
        "    else:\n",
        "      prompt = genre_name + \" | \"\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + \" | \" + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "id": "aeBjvvPfHP0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8069fed5-7839-4c77-cf6e-b7918740de90"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | ier. <b> GITTES </b> Well, I guess you do. <b> DENNIS </b> I'm glad you're happy about this, Harry. That puts her to work. <b> GITTES </b> You're a good man. <b> (THEN) </b> It's a good job. <b> EXT. MULECY </b> As a limousine starts to roll down the mountain road, Gittes and Burke emerge on the street flanked by FBI Agents. Burke has an FBI BADGE pinned to his back, identifying the man as FBI Agent Gittes. <b> BURKE </b> Gittes. <b> GITTES </b> So what the hell's he doin' with this guy now? <b> BURKE </b> You don't know that guy. He used to live in the city. The guy's the real deal. He always had a weakness for special- forces work. (shaking Burke's arm) How about you take this guy and see how he reacts. <b> GITTES </b> Burke's a good man. <b> BURKE </b> And you know what I'm sayin'? 'Yeah, you got a lot on him, too.' Gittes is taken aback by Burke's tough exterior. <b> INT. TOWNHOUSE - OLD TIMER TAVERN </b> Burke and Gittes enter the empty diner to find Burke and Gittes, dressed in old, low-cut white T-shirts. Gittes has his FBI BADGE pinned to his back, FBI BADGE hanging from it. <b> BURKE </b> So the Bureau's still looking for him. <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> 103. </b> <b> CONTINUED: </b> <b> GITTES </b> You're kidding, right? <b> BURKE </b> I'm not. The guy's a real pain in the ass. <b> GITTES </b> Oh, well. What do we do? Why don't we just tell the cops? You'll get your money's worth. <b> BURKE </b> It's going to be a real fuckin' bust this time. I have to clean up. <b> GITTES </b> You've got to clean up before that cop's gonna bust you. <b> BURKE </b> I won't do it, Burke. I'm clean. Gittes nods, nods, and they head toward the door. Burke knocks. <b> BURKE </b> Burke, what is this? <b> CUT TO: </b> <b> INT. TOWNHOUSE - OLD TIMER TAVERN </b> We see Burke and Gittes enter. <b> BURKE </b> So... I just realized I don't really have any special feelings for the guy. <b> GITTES </b> (re: Burke) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ier. <b> GITTES </b> Well, I guess you do. <b> DENNIS </b> I'm glad you're happy about this, Harry. That puts her to work. <b> GITTES </b> You're a good man. <b> (THEN) </b> It's a good job. <b> EXT. MULECY </b> As a limousine starts to roll down the mountain road, Gittes and Burke emerge on the street flanked by FBI Agents. Burke has an FBI BADGE pinned to his back, identifying the man as FBI Agent Gittes. <b> BURKE </b> Gittes. <b> GITTES </b> So what the hell's he doin' with this guy now? <b> BURKE </b> You don't know that guy. He used to live in the city. The guy's the real deal. He always had a weakness for special- forces work. (shaking Burke's arm) How about you take this guy and see how he reacts. <b> GITTES </b> Burke's a good man. <b> BURKE </b> And you know what I'm sayin'? 'Yeah, you got a lot on him, too.' Gittes is taken aback by Burke's tough exterior. <b> INT. TOWNHOUSE - OLD TIMER TAVERN </b> Burke and Gittes enter the empty diner to find Burke and Gittes, dressed in old, low-cut white T-shirts. Gittes has his FBI BADGE pinned to his back, FBI BADGE hanging from it. <b> BURKE </b> So the Bureau's still looking for him. <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> 103. </b> <b> CONTINUED: </b> <b> GITTES </b> You're kidding, right? <b> BURKE </b> I'm not. The guy's a real pain in the ass. <b> GITTES </b> Oh, well. What do we do? Why don't we just tell the cops? You'll get your money's worth. <b> BURKE </b> It's going to be a real fuckin' bust this time. I have to clean up. <b> GITTES </b> You've got to clean up before that cop's gonna bust you. <b> BURKE </b> I won't do it, Burke. I'm clean. Gittes nods, nods, and they head toward the door. Burke knocks. <b> BURKE </b> Burke, what is this? <b> CUT TO: </b> <b> INT. TOWNHOUSE - OLD TIMER TAVERN </b> We see Burke and Gittes enter. <b> BURKE </b> So... I just realized I don't really have any special feelings for the guy. <b> GITTES </b> (re: Burke)  COMEDY | iz no good. <b> BURKE </b> You know he was a good man. <b> GITTES </b> Yeah, okay. <b> BURKE </b> I mean he was a good man. Burke and Gittes watch Burke and Gittes enter. Burke stands at the counter in the empty diner, watching them. <b> (CONTINUED) </b> <b>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ier. <b> GITTES </b> Well, I guess you do. <b> DENNIS </b> I'm glad you're happy about this, Harry. That puts her to work. <b> GITTES </b> You're a good man. <b> (THEN) </b> It's a good job. <b> EXT. MULECY </b> As a limousine starts to roll down the mountain road, Gittes and Burke emerge on the street flanked by FBI Agents. Burke has an FBI BADGE pinned to his back, identifying the man as FBI Agent Gittes. <b> BURKE </b> Gittes. <b> GITTES </b> So what the hell's he doin' with this guy now? <b> BURKE </b> You don't know that guy. He used to live in the city. The guy's the real deal. He always had a weakness for special- forces work. (shaking Burke's arm) How about you take this guy and see how he reacts. <b> GITTES </b> Burke's a good man. <b> BURKE </b> And you know what I'm sayin'? 'Yeah, you got a lot on him, too.' Gittes is taken aback by Burke's tough exterior. <b> INT. TOWNHOUSE - OLD TIMER TAVERN </b> Burke and Gittes enter the empty diner to find Burke and Gittes, dressed in old, low-cut white T-shirts. Gittes has his FBI BADGE pinned to his back, FBI BADGE hanging from it. <b> BURKE </b> COMEDY | urn, huh? What brings you out here? <b> GITTES </b> (looking at Burke) I've got news for you, Bill. My office told me it's about time you took me back. <b> (MORE) </b> <b>----------------------------------------------------------------------------------------------------- </b><b> 59. </b> <b> GITTES (CONT'D) </b> So I'm going to go up to the Sheraton and tell Mr. Reynolds I'm serious on him now and I'm going to take over and make sure he gets the money he's looking for and don't leave. Then I'm going to go watch this body count the rest of his life and he dies. I'm sorry. <b> BURKE </b> Good. <b> GITTES </b> So, I'll come back. <b> BURKE </b> Why don't you come to the Sheraton? <b> GITTES </b> Because I want you to know that I'm coming. There's a knock on the front door. They go to open the door. <b> GITTES (CONT'D) </b> There's a knock. <b> KELVIN (O.S.) </b> Hey, Gittes, what are you doing here? <b> GITTES </b> This is my story now. My whole life. <b> KELVIN (O.S.) </b> I'm on the sleazoid train to Chicago. <b> GITTES ACTION | </b> What are you talking about? <b> KELVIN (O.S.) </b> I wanted to see the trailer park. Gittes looks at the time ticking away. <b> GITTES </b> Well, thanks for asking. I don't think you've got the time...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ier. <b> GITTES </b> Well, I guess you do. <b> DENNIS </b> I'm glad you're happy about this, Harry. That puts her to work. <b> GITTES </b> You're a good man. <b> (THEN) </b> It's a good job. <b> EXT. MULECY </b> As a limousine starts to roll down the mountain road, Gittes and Burke emerge on the street flanked by FBI Agents. Burke has an FBI BADGE pinned to his back, identifying the man as FBI Agent Gittes. <b> BURKE </b> Gittes. <b> GITTES </b> So what the hell's he doin' with this guy now? <b> BURKE </b> You don't know that guy. He used to live in the city. The guy's the real deal. He always had a weakness for special- forces work. (shaking Burke's arm) How about you take this guy and see how he reacts. <b> GITTES </b> Burke's a good man. <b> BURKE </b> And you know what I'm sayin'? 'Yeah, you got a lot on him, too.' Gittes is taken aback by Burke's tough exterior. <b> INT. TOWNHOUSE - OLD TIMER TAVERN </b> Burke and Gittes enter the empty diner to find Burke and Gittes, dressed in old, low-cut white T-shirts. Gittes has his FBI BADGE pinned to his back, FBI BADGE hanging from it. <b> BURKE </b> COMEDY | urn, huh? What brings \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " urn, huh? What brings  COMEDY | icles to this place? They don't even have a TV or a computer! <b> LOU </b> I didn't think it was that big to come up and do a hik-a with my stuff. <b> TED </b> We'll have to give it a little try. <b> CUT TO: </b> <b> INT. ANOTHER PART OF THE PARK - NIGHT </b> <b> TED </b> You know, I've been thinking about my wife. What if I made this whole thing about her? If I told her I wanted to get married or something. I wouldn't want to let her go. You know what I mean? I wouldn't take it, not unless I knew the answer. But then I was wondering if maybe we could go into my own private world where she'd be able to accept that I'd be good at it. <b> LOU </b> (excited) Then what? <b> TED </b> Then I could tell her it was hopeless. That I'm not going to marry her. She might be unhappy. Maybe she'll have tears in her eyes. <b> LOU </b> I'm not gonna marry her. I want to be the father. <b> TED </b> Me neither. If I'm gonna be the father, I need someone like you to take charge. I need someone with some experience to take charge. Like me, I know, and I don't like it. I know, all of a sudden I realize it's impossible. I know I shouldn't let her go. It would be good for us if she could figure out what she wanted. <b> LOU </b> Look, I'm not gonna marry her. I have to take a moment alone. Let me put it this way: she'll need help. <b> TED </b> (confused) What? <b> LOU </b> I know she'll need help. But she's too dangerous. I'll take her to Miami. That's where I'll be safe. I'll deal with her. <b> TED </b> But she's dangerous. <b> LOU </b> Exactly. Look at me. I always know I'm wrong. <b> TED </b> You can trust her, Lou. This is the best thing I've ever done for you. <b> LOU </b> She's not like you. She's not like you. <b> TED </b> She's like me. She's like us. <b> LOU </b> She's like everybody else. He pulls the gun from his jacket. <b> TED </b> How did you know that? FANTASY | <b> LOU </b> We were together for the first time. She told me everything... <b> TED </b> She knew about you? <b> LOU </b> I don't know. Why would I say that? <b> TED </b> Because you were my father. <b> LOU </b> She made me memorize every line. What do you have to say to understand her? I mean, she's not like you. She's like a kid who can't understand anything. A beat. <b> TED </b> (a beat, then:) I guess I should tell her I was sorry. <b> LOU </b> Yes. He looks at Ted. <b> TED </b> I don't trust anybody. <b> LOU </b> I know. <b>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " urn, huh? What brings  COMEDY | icles to this place? They don't even have a TV or a computer! <b> LOU </b> I didn't think it was that big to come up and do a hik-a with my stuff. <b> TED </b> We'll have to give it a little try. <b> CUT TO: </b> <b> INT. ANOTHER PART OF THE PARK - NIGHT </b> <b> TED </b> You know, I've been thinking about my wife. What if I made this whole thing about her? If I told her I wanted to get married or something. I wouldn't want to let her go. You know what I mean? I wouldn't take it, not unless I knew the answer. But then I was wondering if maybe we could go into my own private world where she'd be able to accept that I'd be good at it. <b> LOU </b> (excited) Then what? <b> TED </b> Then I could tell her it was hopeless. That I'm not going to marry her. She might be unhappy. Maybe she'll have tears in her eyes. <b> LOU </b> I'm not gonna marry her. I want to be the father. <b> TED </b> Me neither. If I'm gonna be the father, I need someone like you to take charge. I need someone with some experience to take charge. Like me, I know, and I don't like it. I know, all of a sudden I realize it's impossible. I know I shouldn't let her go. It would be good for \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " icles to this place? They don't even have a TV or a computer! <b> LOU </b> I didn't think it was that big to come up and do a hik-a with my stuff. <b> TED </b> We'll have to give it a little try. <b> CUT TO: </b> <b> INT. ANOTHER PART OF THE PARK - NIGHT </b> <b> TED </b> You know, I've been thinking about my wife. What if I made this whole thing about her? If I told her I wanted to get married or something. I wouldn't want to let her go. You know what I mean? I wouldn't take it, not unless I knew the answer. But then I was wondering if maybe we could go into my own private world where she'd be able to accept that I'd be good at it. <b> LOU </b> (excited) Then what? <b> TED </b> Then I could tell her it was hopeless. That I'm not going to marry her. She might be unhappy. Maybe she'll have tears in her eyes. <b> LOU </b> I'm not gonna marry her. I want to be the father. <b> TED </b> Me neither. If I'm gonna be the father, I need someone like you to take charge. I need someone with some experience to take charge. Like me, I know, and I don't like it. I know, all of a sudden I realize it's impossible. I know I shouldn't let her go. It would be good for  COMEDY | icles. It might even have an impact on all of us. <b> LOU </b> That could be good for a lot of people. <b> TED </b> I wish there was something we could do. Some kind of spiritual connection. <b> CUT TO: </b> <b> INT. A ROOM - ANOTHER NIGHT </b> <b> LOU </b> Jesus, he's just a guy. (beat) What do you think? <b> TED </b> He just wants to be good. <b> CUT TO: </b> <b> INT. A BATHROOM - ANOTHER NIGHT </b> <b> LOU </b> He's just a guy. He's just a guy. I think that would be great. <b> TED </b> Yeah, but the thing I don't understand is how he can be nice to me. You know, this is such a totally different situation for him. <b> LOU </b> Why are you crying? <b> TED </b> Because he really wants me to believe he's nice to me. <b> LOU </b> Yeah, but he says he's not like that. <b> TED ACTION | </b> Well, he knows. He's just like you. You're like that guy who's always gotta be nice. <b> LOU </b> Right. <b> TED </b> Right, right. <b> LOU </b> He knows, too. <b> TED </b> Right. <b> LOU </b> Yeah. But I know something... <b> TED </b> Yeah, it's probably true. <b> LOU </b> Yeah. <b> TED </b> Well, he wants me to believe he's nice to me. <b> LOU </b> No, he's like-- <b> TED </b> Yeah. <b> L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " icles to this place? They don't even have a TV or a computer! <b> LOU </b> I didn't think it was that big to come up and do a hik-a with my stuff. <b> TED </b> We'll have to give it a little try. <b> CUT TO: </b> <b> INT. ANOTHER PART OF THE PARK - NIGHT </b> <b> TED </b> You know, I've been thinking about my wife. What if I made this whole thing about her? If I told her I wanted to get married or something. I wouldn't want to let her go. You know what I mean? I wouldn't take it, not unless I knew the answer. But then I was wondering if maybe we could go into my own private world where she'd be able to accept that I'd be good at it. <b> LOU </b> (excited) Then what? <b> TED </b> Then I could tell her it was hopeless. That I'm not going to marry her. She might be unhappy. Maybe she'll have tears in her eyes. <b> LOU </b> I'm not gonna marry her. I want to be the father. <b> TED </b> Me neither. If I'm gonna be the father, I need someone like you to take charge. I need someone with some experience to take charge. Like me, I know, and I don't like it. I know, all of a sudden I realize it's impossible. I know I shouldn't let her go. It would be good for  COMEDY | ike. I would do it. <b> TED </b> You're probably right. We could probably settle up together after work. <b> LOU </b> You mean after work? <b> TED </b> That might be a possibility. <b> LOU </b> I'm very, very happy with this idea. <b> TED </b> With a million dollars?? <b> CUT TO: </b> <b> EXT. THE COUNCIL BUILDING - LATER </b> The whole park is lit up with bright, colorful lights and a huge, banner reading: CITY <b> COUNCIL - BALTIMORE </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> The NEW ERA AGENCY is one of several offices that have been converted into WAREHOUSE MARKETS and CUBICLES. Some are huge and have long lines of CUSTOMERS waiting to be purchased, most are small, SCARY SERVICE CRATES, others are overflowing with junk, etc. All of \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ike. I would do it. <b> TED </b> You're probably right. We could probably settle up together after work. <b> LOU </b> You mean after work? <b> TED </b> That might be a possibility. <b> LOU </b> I'm very, very happy with this idea. <b> TED </b> With a million dollars?? <b> CUT TO: </b> <b> EXT. THE COUNCIL BUILDING - LATER </b> The whole park is lit up with bright, colorful lights and a huge, banner reading: CITY <b> COUNCIL - BALTIMORE </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> The NEW ERA AGENCY is one of several offices that have been converted into WAREHOUSE MARKETS and CUBICLES. Some are huge and have long lines of CUSTOMERS waiting to be purchased, most are small, SCARY SERVICE CRATES, others are overflowing with junk, etc. All of  COMEDY | ills is a series of TORTURES wrapped in plastic bags, and sold. <b> ANDREW WALSH </b> They work as an arm's length store. <b> ANDREW WALSH (V.O.) </b> I've seen the photos on the walls. <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b\n",
            " ike. I would do it. <b> TED </b> You're probably right. We could probably settle up together after work. <b> LOU </b> You mean after work? <b> TED </b> That might be a possibility. <b> LOU </b> I'm very, very happy with this idea. <b> TED </b> With a million dollars?? <b> CUT TO: </b> <b> EXT. THE COUNCIL BUILDING - LATER </b> The whole park is lit up with bright, colorful lights and a huge, banner reading: CITY <b> COUNCIL - BALTIMORE </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> The NEW ERA AGENCY is one of several offices that have been converted into WAREHOUSE MARKETS and CUBICLES. Some are huge and have long lines of CUSTOMERS waiting to be purchased, most are small, SCARY SERVICE CRATES, others are overflowing with junk, etc. All of  COMEDY | ills is a series of TORTURES wrapped in plastic bags, and sold. <b> ANDREW WALSH </b> They work as an arm's length store. <b> ANDREW WALSH (V.O.) </b> I've seen the photos on the walls. <b> A NEW ERA AGENCY </b> <b> A NEW ERA AGENCY </b> \n",
            "COMEDY |  |  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above code very often generates movie dialogue in French... I don't know why"
      ],
      "metadata": {
        "id": "bh2p6UEdkjqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: Sometimes the code above generates a different genre name than the one in the prompt"
      ],
      "metadata": {
        "id": "pPCSSFaqrJGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: Sometimes the code above generates 2 genre names such that the second genre tag is near the end or the beginning of the sequence (and not halfway)"
      ],
      "metadata": {
        "id": "TdecM7b8imgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above code generates good, but repetitive output about 40% of the time (I ran it ~10 times)"
      ],
      "metadata": {
        "id": "33wwqKbnqF6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try generating with the sequence that comes after the midway genre tag (without the midway genre tag):"
      ],
      "metadata": {
        "id": "jI7kDb8E8lPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "genre_name = \"COMEDY\"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  print(\"prompt:\")\n",
        "  print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  #print(\"sample_outputs:\")\n",
        "  #print(sample_outputs)\n",
        "  #print(\"sample_outputs[0]:\")\n",
        "  #print(sample_outputs[0])\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  print(\"len(sample_output_decoded_parts):\")\n",
        "  print(len(sample_output_decoded_parts))\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  try:\n",
        "    prompt = sample_output_decoded_parts[2][3:] # gets rid of the \" | \"\n",
        "  except: # on this rare occasion, GPT-2 didn't generate the second genre_name in the middle of the generated sequence\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_after_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[half_sample_output_decoded_tokens_length:sample_output_decoded_tokens_length]:\n",
        "      prompt_after_genre_name_and_vertical_line += token + \" \"\n",
        "    prompt = prompt_after_genre_name_and_vertical_line\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "m1oX2JsnxV6X",
        "outputId": "b3ced4ff-82e8-49cb-919b-bf5b1ff5e589"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt:\n",
            "COMEDY | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(sample_output_decoded_parts):\n",
            "2\n",
            "COMEDY | ieta il est a peut encore! Ils se retournent au chien � sept d'une grande musique de la vitrum. <b> LORI </b> Monsieur Tonton, o� est le regard! <b> TONNO </b> Voil�, ma petite j�ureur. <b> LORI </b> En faisait des deux pour voyons. Une autre fois est tomb�e ses bougies pour les choses. Tonton enjoint Gabriel qui se retourne vers le haut de la musique de ses draps. Gabriel se retourne vers le haut de la musique, mais vu leurs en faisait des poches. <b> GABRIEL FOUQUET </b> Monsieur Gabriel est inscrit : Gabriel et les retrouves des ducs bougies, et que le autre fois descend du mur, on parlant le haut de sa musique. <b> LORI </b> Faut tout de nous, monsieur, qui �tes l'argenter au milieu de la musique. Il se retourne vers Gabriel, qui est assis au milieu de la musique, et regarde Gabriel. Lorsl�e sort un bonbon dans le mur. <b> LORI </b> Pardonnez-moi, Monsieur Tonton, vous avez le mauvaire, la musique est inscrit : Gabriel. <b> GABRIEL FOUQUET </b> Une autre fois mieux pas trop d�cid�e, on est le m�me. Un petit pomme jamais faut mieux jamais avant la porte de l'escalier. Lorsl�e sort en robe de l'escalier, sur lequel il se penche vers la main. Lorsl�e finissent son nom de la musique. <b> LORI </b> Un quoi? <b> LES MISERABLES </b> Viens, vous me voulez, monsieur Gabriel. <b> LES MISERABLES </b> Vous voulez, monsieur. <b> GABRIEL FOUQUET </b> Monsieur Gabriel, tu vas plus c'est pas comme tu vas plus c�t�. Pendant que le p�re est venu pour les s�r�pants. Lorsl�e sort de la voix. <b> LORI </b> Chaimez-moi, c'est un peu �tait lui aussi! Lorsl�e sort de la voix et le regarde Gabriel. <b> LORI </b> Oui, monsieur! Gabriel! Gabriel vient d�cid�e et l'arr�te du haut de sa voix. <b> LES MISERABLES </b> Un quoi? <b> GABRIEL FOUQUET </b> Vous voulez, monsieur. Il a l'arr�te lentement de Gabriel. <b> LES MISERABLES </b> Je vois que j'ai pas dis que je suis revenu, c'est plus venir\n",
            "prompt:\n",
            "Gabriel. <b> GABRIEL FOUQUET </b> Une autre fois mieux pas trop d�cid�e, on est le m�me. Un petit pomme jamais faut mieux jamais avant la porte de l'escalier. Lorsl�e sort en robe de l'escalier, sur lequel il se penche vers la main. Lorsl�e finissent son nom de la musique. <b> LORI </b> Un quoi? <b> LES MISERABLES </b> Viens, vous me voulez, monsieur Gabriel. <b> LES MISERABLES </b> Vous voulez, monsieur. <b> GABRIEL FOUQUET </b> Monsieur Gabriel, tu vas plus c'est pas comme tu vas plus c�t�. Pendant que le p�re est venu pour les s�r�pants. Lorsl�e sort de la voix. <b> LORI </b> Chaimez-moi, c'est un peu �tait lui aussi! Lorsl�e sort de la voix et le regarde Gabriel. <b> LORI </b> Oui, monsieur! Gabriel! Gabriel vient d�cid�e et l'arr�te du haut de sa voix. <b> LES MISERABLES </b> Un quoi? <b> GABRIEL FOUQUET </b> Vous voulez, monsieur. Il a l'arr�te lentement de Gabriel. <b> LES MISERABLES </b> Je vois que j'ai pas dis que je suis revenu, c'est plus venir \n",
            "len(sample_output_decoded_parts):\n",
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-afe507d4da19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len(sample_output_decoded_parts):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgenre_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# gets rid of the \" | \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above code crashed in all 5 times I ran it since **sample_output_decoded_parts** had the length of 1. This isn't expected behaviour, so I'm moving on from this code."
      ],
      "metadata": {
        "id": "upbW6Oi0DKvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let me try different k values:"
      ],
      "metadata": {
        "id": "Ybm2i0ywFOlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try **top_k = 10**:"
      ],
      "metadata": {
        "id": "8qiHRwhGxQm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "#prompt = \"<|startoftext|>\" # if I include this in the prompt, it generates garbage\n",
        "genre_name = \"COMEDY\"\n",
        "#prompt += \" \" + genre_name + \" | \"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=10, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  # debug prints\n",
        "  #print(\"sample_outputs:\")\n",
        "  #print(sample_outputs)\n",
        "  #print(\"sample_outputs[0]:\")\n",
        "  #print(sample_outputs[0])\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  try:\n",
        "    prompt = genre_name + sample_output_decoded_parts[2]\n",
        "  except: # on this rare occasion, GPT-2 didn't generate the second genre_name in the middle of the generated sequence\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_after_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[half_sample_output_decoded_tokens_length:sample_output_decoded_tokens_length]:\n",
        "      prompt_after_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints\n",
        "    #print(\"prompt_after_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_after_genre_name_and_vertical_line)\n",
        "    prompt = genre_name + \" | \" + prompt_after_genre_name_and_vertical_line\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "id": "bwE4PUrPFP-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "outputId": "1590dd1d-e03a-45d9-bf82-93b06da6307a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | izhts. Asael suddenly looks up. <b> ASAEL </b> They have the gates. They've got the Ark. They've got the Ark. <b> GABRIEL </b> But they have no way! <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> </b> SALMON Revision - 8-18-07 71A. <b> 73 CONTINUED: 73 </b> <b> ASAEL </b> No they don't! It's too dangerous. <b> GABRIEL </b> They must have it. The gates have to be locked. <b> ASAEL </b> No they won't! They can't! <b> GABRIEL </b> They've got it, they must have it! <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> </b> SALMON Revision - 8-18-07 71B. <b> 73 CONTINUED: (2) 73 </b> <b> GABRIEL </b> <b> BUT THEY GOT THE KORFMAN'S KEYS! </b> <b> ASAEL </b> <b> THEY GOT THE KORFMAN'S KEYS! </b> <b> GABRIEL </b> <b> THEY GOT THE KORFMAN'S KEYS! </b> <b> ASAEL </b> They're locked. <b> GABRIEL </b> Locked! <b> ASAEL </b> They've got the gates, the Ark. The people are coming! <b> GABRIEL </b> <b> THEY'LL GIVE IT UP OR THEY'LL GET </b> <b> KILL US ALL! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY GOT THE KORFMAN'S KEYS, THEY </b> <b> GOT THE KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WERE GONNA GET THE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP OR THEY WENT UP </b> <b> THE KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP OR THEY WENT UP </b> <b> THE KORFMAN'S KEYS! </b> RESCUE looks at Gabriel. He is furious. <b> RESCUE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP THE KORFMAN'S KEYS! </b> <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> </b> SALMON Revision\n",
            "COMEDY | They've got the gates, the Ark. The people are coming! <b> GABRIEL </b> <b> THEY'LL GIVE IT UP OR THEY'LL GET </b> <b> KILL US ALL! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY GOT THE KORFMAN'S KEYS, THEY </b> <b> GOT THE KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WERE GONNA GET THE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP OR THEY WENT UP </b> <b> THE KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP OR THEY WENT UP </b> <b> THE KORFMAN'S KEYS! </b> RESCUE looks at Gabriel. He is furious. <b> RESCUE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP THE KORFMAN'S KEYS! </b> <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> </b> SALMON Revision  \n",
            "COMEDY | THEY WENT UP </b> <b> THE KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP OR THEY WENT UP </b> <b> THE KORFMAN'S KEYS! </b> RESCUE looks at Gabriel. He is furious. <b> RESCUE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP THE KORFMAN'S KEYS! </b> <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> </b> SALMON Revision   \n",
            "COMEDY | <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> KORFMAN'S KEYS! </b> <b> RESCUE </b> <b> GABRIEL </b> <b> BUT THEY WENT UP THE KORFMAN'S KEYS! </b> <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> </b> SALMON Revision    \n",
            "COMEDY | WENT UP THE KORFMAN'S KEYS! </b> <b> (CONTINUED) </b> <b> </b> <b> </b> <b> </b> <b> </b> SALMON Revision     \n",
            "COMEDY | <b> </b> <b> </b> <b> </b> SALMON Revision      \n",
            "COMEDY | SALMON Revision       \n",
            "COMEDY |       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY |      \n",
            "COMEDY |     \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-6d0940784dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# print the last part of the last generated line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try **top_k = 100**:"
      ],
      "metadata": {
        "id": "kLGnPNyjxS3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "#prompt = \"<|startoftext|>\" # if I include this in the prompt, it generates garbage\n",
        "genre_name = \"COMEDY\"\n",
        "#prompt += \" \" + genre_name + \" | \"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=100, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  # debug prints\n",
        "  #print(\"sample_outputs:\")\n",
        "  #print(sample_outputs)\n",
        "  #print(\"sample_outputs[0]:\")\n",
        "  #print(sample_outputs[0])\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  try:\n",
        "    prompt = genre_name + sample_output_decoded_parts[2]\n",
        "  except: # on this rare occasion, GPT-2 didn't generate the second genre_name in the middle of the generated sequence\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_after_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[half_sample_output_decoded_tokens_length:sample_output_decoded_tokens_length]:\n",
        "      prompt_after_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints\n",
        "    #print(\"prompt_after_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_after_genre_name_and_vertical_line)\n",
        "    prompt = genre_name + \" | \" + prompt_after_genre_name_and_vertical_line\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0-S0YrkvG8i",
        "outputId": "3bfdedb2-e115-4285-ea7a-e6f73b24f6b2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | irectly in front of him is a small, black glass apparatus. It is a machine designed to control the movement of the water at liquid-level. This device is known as a \"water port.\" There are hundreds of sensors that are wired to it, operated by a small, wired-to-the- environment machine. Once the control is complete, the water port slowly lowers, slowly lowering. As the pressure increases, the glass sphere will slowly lower, until it is level with the crystalline floor. This is known as the \"V.\" <b> SPHINX </b> (in awe) This is the real thing... <b> ZAPHOD </b> Yes, it is... The ship is about ten meters wide. Half the atmosphere in the room will be contained inside a glass sphere. All of this will in turn produce tremendous heat and tremendous electromagnetic pulse that will spread throughout the ship. The glass sphere will slow at about 5 meters per second. Splashing is impossible, even impossible in an underground sea. Suddenly, in the sphere itself, a huge mass of blue-white LIQUID oozes out of the ice. Startling in its container is a giant, green laser light. The blue laser light spreads quickly across the ice. <b> ZAPHOD </b> See this. The laser light spins, and penetrates the cylinder in its container, splitting open the cylinder in two halves. The water in the sphere begins to pour out, and disappears. As the blue light hits the ice in the sphere, it also dissolves into fiery pieces. <b> ANGLE ON ZAPHOD </b> For a moment he is frozen. Then, he begins to sink in. <b> ZAPHOD </b> Where am I? <b> SPHINX </b> Where you are. Your ship... Where's my mother? <b> ZAPHOD </b> How long will it take to recover? <b> SPHINX </b> (painfully) I can't... Where are you? No answer. <b> SPHINX </b> (hoarse) Don't tell me. Your mother... ZAPHOD lies still for a moment, his forehead bandaged. <b> ZAPHOD </b> Your mother? What do you mean? A broken, barely audible lullaby? <b> ZAPHOD </b> You were with her. <b> ZAPHOD </b> You knew. I knew. <b> SPHINX </b> I can't understand this, Father... <b> ZAPHOD </b> It's no use, but it'll work. Go away. You're safe, you're safe, I promise. <b> CUT TO: </b> <b> INT. ENTERPRISE - BRIDGE - LATER </b> The ship appears on a bridge of light. Everyone is \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | standing around their stations, and everyone is in a state of shock. <b> SULU </b> No one move! A collective breath of relief goes through the ship. <b> SCIMP </b> They're okay. It's a miracle. <b> PICARD </b> It's great to be safe here... <b> KLUTE </b> Let's get the hell out of here. <b> PICARD </b> I'm a captain. If we're going to stay this ship, we need to keep moving. <b> KIRK </b> Sir, we have no time to argue. All of a sudden the ship's engines go out in a series of sputters, then stalls. <b> JIMMY PIG </b> They'll stop! All engines go out! Jimmy Pig turns away in disgust. <b> KIRK </b> Aw, crap. I didn't even know that ship had half a minute to stop. (to Kirk) Jim, you okay? <b> KIRK </b> I'm all right. <b> JIMMY PIG </b> Can't you get past the fact that there's a giant, silent ship in the sky that's going to die? Everyone stops what they are doing. <b> HECK </b> We're not going to die here. Kirk lets this sink in. <b> KIRK </b> You mean you want to tell us why? <b> HECK </b> I mean, in the old days, everyone thought they were the dumbest ship in the world, but now they're all scared. I mean, the damn thing's dead! Kirk lets this sink in. He notices the tiny control panels that still hold his station. <b> HECK </b> Look, Kirk... this thing hasn't failed. We've been sent up here for three years-- <b> KIRK </b> --Three years-- <b> HECK </b> We've been sent up for three years-- <b> KIRK </b> --and four years. <b> HECK </b> That's not good. <b> KIRK </b> You really think we should be stuck here all this time? Why are we all here? Why are we being sent up here and being scared? <b> HECK </b> Maybe because we are stupid, Jim. Because we never will be stupid-- <b> JIMMY PIG </b> All right, all right, go ahead, but ask questions. Jim sits before Kirk and starts to ask questions. <b> JIMMY PIG </b> Are we really still friends? Are we the only friends in the whole ship? Are we really still friends? Jim stops. He tries to think about what to ask. <b> JIMMY PIG \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | </b> (continuing; nervous) Of course not-- <b> KIRK </b> Because of us? We may be friends but we're not the only friends in the entire ship. We might even be the only one who will ever be the friendliest ship in the whole world. I'm going to ask them. <b> HECK </b> I'm going to ask them now, Jim. I'll tell them the truth, and tell them that I was right. Jimmy nods. A beat. Kirk realizes he doesn't have to. Finally: <b> KIRK </b> What do you think? I feel like an idiot. <b> HECK </b> (jumping in) You're not an idiot, son. Kirk, this is serious. Do you want to get serious? You better start thinking of the consequences of the second century being avoided. <b> KIRK </b> I can't. I'm trying to go home. <b> HECK </b> Then you'll want to try and tell me why you're here, too. If you do, we may not be friends but we're not the only friends in this ship. And for all this you were ordered to die, right? <b> KIRK </b> For all this, I'm not going to die. Kirk stands up. <b> KIRK </b> Please. Just let me have my life. I have an eternity of life. He stands there in silence, as if he knew that he might experience some kind of crisis. Then: <b> HECK </b> You're going to try and tell me what it is you want to do. <b> KIRK </b> What do you want to do? <b> HECK </b> First of all, you don't have to tell me. Second, even if you tried to shoot your brother, the price of surrendering your life would still be the same. We're all mortal, okay? <b> KIRK </b> Uh, but-- <b> HECK </b> (frowning) Just trust me. He steps closer, and KIRK gets the hint. <b> KIRK </b> You don't even know what that means. <b> HECK </b> Just trust me. I'll see you on the landing site. And you and me, we'll be all together. But right now, if that's all you've got to do, then that's all anyone's got. <b> KIRK </b> I've got my life up to my shoulders, I swear. And I'm not going to let you die. But I'm not going to let you leave me. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | You see I'm not going to let you die. <b> HECK </b> (smiling) Okay, let it happen. And while you may not have seen it in me, I'm going to have you back on the force, and I'm going to get off on this alone for about a week. <b> KIRK </b> I gotta get off at the end of the month. <b> HECK </b> You've never been far, Kirk, I'm surprised. But let me tell you, I've got work to do. He moves toward the door and out. The moment passes. Kirk turns back. <b> CUT TO: </b> <b> 125 EXT. STREET - DUSK </b> Kirk walking home from work. He stops. He looks up and down the street, not looking at the street or the street or the house. He runs his hand through his hair. <b> CUT TO: </b> <b> 126 EXT. DESERT ROAD - NIGHT </b> Kirk walks alone, not looking at himself in the sun. A long, dark silence. He looks at his watch. <b> 128 EXT. HIGHWAY - NIGHT </b> Kirk watches the night. He starts walking. The lonely, empty desert. <b> CUT TO: </b> <b> 129 EXT. SAN FRANCISCO SKYLINE - DUSK </b> Kirk walks down a twisting, twisting road in San Francisco. He pauses. No one is there. He walks a few yards and stops. He watches. The skyline of San Francisco is still only a quarter of a mile away, overhanging from the sea, the faint glow of a summer afternoon sun. Kirk doesn't stop walking because -- The desert reaches the top of a distant rise. It is a long, stunningly steep hill-side. Beyond is the entire Pacific. There is no point in wandering around like that for a moment. All that can be seen are the mountains, the empty plain walls and the swaying jutting rock. Kirk begins walking, his hands clasped in front of him, moving his arms in front of him, as though not aware of the landscape. His head resting on his hands, he feels the silence and the soft soft strains of rock playing in his ears. In the distance, he sees the ocean. And the city. His fingers reach out toward the horizon, the soft wind driving off an almost ethereal beauty. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | And then, the sound of a distant horn. Kirk freezes. The horn. Kirk runs along the horizon, stopping only to stare out at the sea. From behind the hill, a tiny FIGURE rockets out into the setting sun. And the FIGURE continues on as though looking in Kirk's direction. The FIGURE stands at the horizon, looking at Kirk, and Kirk stops. The FIGURE turns and looks over his shoulder at Kirk. <b> FIGURE </b> You said you didn't want to go out in public. A moment of silence. <b> FIGURE </b> That's true. You know who they are... The FIGURE raises the gun, aims at Kirk. <b> FIGURE </b> No, I'm telling you. I wasn't there. You don't know how I could be there. <b> KIRK </b> That's bullshit. <b> FIGURE </b> They're human. When we're human, we always get what we want. I guess we got our start in life, Kirk. And then we made the wrong choice. We decided not to run. <b> KIRK </b> Shit. Why not? There are lots of answers in here. (off his look) I can't even think of one. The FIGURE is staring back at Kirk, his face a mask of anger, sadness. He seems to have lost control. He shakes his head, tears starting to stand in his eyes. A long beat. <b> FIGURE </b> (to Kirk) Your boy's no different than us. And you, we don't. <b> KIRK </b> No? <b> FIGURE </b> You don't even trust me. She gives him a hard look, then smiles. <b> FIGURE </b> This is the kind of arrogance you follow when you care for others. You might have had a son... but not a real father. And you've let him run away before. She stares at Kirk. A long beat. <b> FIGURE </b> A father can't rule his own fate. He thinks it's all a dream... but it's not. He has no choice, either. A long beat. <b> FIGURE </b> Have you been to the forest, or what? A long beat. <b> FIGURE </b> A sacred place. That's where we belong. She reaches down, takes Kirk's hand. And they lock eyes. They hold each other, their eyes locked in a gaze that is almost childlike. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | And Kirk breaks down, a little unsteady from that ordeal. He shakes his head. And we see the look on his face. He's lost. <b> KIRK </b> Yeah? Was that what it said? <b> FIGURE </b> You got a chance to ask it. <b> KIRK </b> Huh? <b> FIGURE </b> Just ask it. A long moment. <b> FIGURE </b> We didn't know what we were doing here. <b> KIRK </b> How do I know? She holds his eyes. <b> KIRK </b> I don't know any... she'll probably know. He squeezes her tighter. She resists. <b> KIRK </b> I don't know what I'm supposed to say. <b> FIGURE </b> You want some advice, son? A long moment. The MAN is waiting for them. <b> MAN </b> Do what you have to do, boy. You're here to protect me... <b> KIRK </b> I don't have a choice. He looks at her. A moment. Then he gets up. <b> MAN </b> (to Kirk) We're going to protect you, this time until the end. A beat. But Kirk nods. <b> MAN </b> Don't ever forget that man and us together, or I'll come after you. And we can tell by the look on his face. What might've been. And he turns, and heads out through the front door. <b> EXT. BANK - DAY </b> <b> ON KIRK </b> As he strides along the sidewalk. <b> EXT. WOODS - DAY </b> As Kirk passes a dead oak tree. Relieved, he reaches over and lifts it, looking down to see it is a hundred feet from where he saw the fire escape. <b> EXT. FRONT YARD - DAY </b> Kirk rounds the corner. Almost at the edge, his jaw sets. He watches a few people run from the bank toward the house. All heads turn, but the people that pass stop. For a moment, it's as if they're seeing nothing, but not the slightest flicker of recognition. And the feeling is mutual. She is frozen by what Kirk sees. <b> KIRK </b> Look. I'm back. It's like she is. I don't think she could have jumped out of the bank... look. <b> ON KIRK </b> His face drops. This is just the beginning. And a new place. Suddenly she isn't there. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | <b> EXT. THE HOUSE - DAY </b> Through the front door, in the dim light of dawn, we see the front porch. Kirk steps into the shadows. <b> CUT TO: </b> <b> INT. BEDROOM - DAY </b> A small bedroom off one of the fifties. Kirk paces inside in his robe, as if he doesn't know what to say. The house is a mess. It's been stripped of his personal possessions. Stuffed posters, newspaper clippings, old photographs, old clothes, old shoes. Kirk just stands there a long beat, staring at nothing. <b> NICOLE (O.S.) </b> And? Kirk snaps the door shut. NICOLE has come in, with groceries and an umbrella from the kitchen. She stands beside the door, but he looks left and right, making sure she's there. <b> NICOLE </b> Mr. Franson, I know the feeling you left before we met. That you... <b> KIRK </b> I wouldn't trade his shoes for your socks! And I'd be very nervous if I told you I liked 'em. <b> NICOLE </b> Of course you would. <b> KIRK </b> This is your house. <b> NICOLE </b> I remember it well. But not so well. So do you. You're very much the same now. <b> KIRK </b> (pleased with himself) That was the most wonderful idea. She looks at him for a long moment, then walks over. <b> NICOLE </b> Just tell me this -- <b> KIRK </b> Where were you living... <b> NICOLE </b> I was moved. (trying to be diplomatic) Where were you --? She stops, not knowing what to say. They're alone now. <b> KIRK </b> (to himself) Yeah, uh, I thought of the whole damn thing, if I could tell. But all I got is a headache -- <b> NICOLE </b> Don't be a drip. You can tell she loves you. Kirk gives her the umbrella. She lifts the bag from the door, still smiling a little. <b> NICOLE </b> You must forgive me... You must forgive me for being so... emotional about... <b> KIRK </b> (not sure where to begin) Uh... I'm not, okay? What do you know about... <b> NICOLE </b> I used to read like your father worked on a bank here. But I'm still kind of a hard case. Yeah, I sort of hate the \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | financial side... He finally gets up from the bed. <b> NICOLE </b> Listen, I was just going to say -- how would you feel if you actually knew that your son was still alive? Kirk nods, agreeing. <b> NICOLE </b> I'm sorry to tell you that it is a long story. And I don't want you to tell me where I am. This is my story now. I've got a long way to go. She gets into the car and starts the engine. As they drive off, we can see inside the car the small man, RONSON, has been watching them get out. <b> EXT. STREET - DAY </b> They come to a stop. <b> NICOLE </b> But, Kirk, isn't it interesting...? What's the point. If this stuff gets to the bottom, I'll never be able to be a father again. (beat) But, Kirk... what's wrong with you? <b> KIRK </b> I don't know. (beat) Maybe I don't need a father anymore. They both look at the street, all expressionless. Then: <b> NICOLE </b> So, you don't expect me to have a heart right now? The two share a look. It almost looks like a kiss. The car pulls over. <b> NICOLE </b> And what do you think of the father? Who does he think of, exactly? <b> KIRK </b> I have no idea. <b> NICOLE </b> But you could use a partner. <b> KIRK </b> A partner doesn't call to me anymore. I can go back to my apartment and we can have dinner tonight. <b> NICOLE </b> I'd appreciate that. She goes back inside the car. After a moment, he turns and walks off, leaving her standing in the street as the car pulls off. She takes a drink, and smiles sadly at Kirk. <b> INT. KIRK'S HOME - DAY </b> Kirk is on the couch playing Gameboy. We PAN up to find Nina's bare legs dangling over his left breast. We hear the SOUNDS of a man's FOOTSTEPS. Then, from across the room, we hear <b> A TELEPHONE. </b> <b> VOICE </b> (over machine) Sorry to bother you, sir. (beat) Mr. Kirk is out of town, and he's a patient of mine. Your call is from our office. Kirk turns off the machine. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | <b> INT. KIRK'S KITCHEN - DAY </b> Kirk is in the kitchen doing dinner. In the background is Nina. Suddenly, his hand drags something from the back. The fingers slip. <b> NINA </b> Oh my God! Is that your son? A smile. He looks at her, a little confused. Nina pinches his cheek. <b> NINA </b> I didn't mean that. I didn't mean that. I just meant that if someone like that happens to me, I can't ever let him do that again. I'll lose it. <b> KIRK </b> What have I done to your son? <b> NINA </b> Nothing. Just nothing. Now, you just go away and get some sleep. Maybe that's all you have left. I'll leave. <b> KIRK </b> We've got to go. <b> NINA </b> Will you just listen to me? This isn't going to be easy. It's not going to be easy. <b> KIRK </b> I know. <b> NINA </b> Look, you look great -- I know you look great. But if you want to have a good time, then let's go get some sleep. Do you want a beer or something? <b> KIRK </b> I don't know what to tell them. <b> INT. UPSTAIRS HALLWAY - DAY </b> As Kirk and Nina go down the hall, he keeps holding his eyes. Nina is still in her bedroom. After a few moments he goes to the stairs and quietly shuts the door. Nina stares at him a moment. Then she goes to the door. She tries the handle. It's locked. She tries again. It's unlocked. She tries the key. But it's locked. <b> INT. KIRK'S APARTMENT - CONTINUOUS </b> Kirk opens the door to the living room, grabs his drink and starts for the bedroom. After a few moments, the door opens a crack and Nina looks out. She's just entered the bedroom, the bedroom and the living room. It's dark. The floor is bare. Everything has a weak shine in it, but it's the truth of her. <b> NINA </b> Hello? <b> KIRK </b> Hello? Nina looks a little embarrassed, but doesn't tell him. <b> NINA </b> You slept? <b> KIRK </b> Yeah. \n",
            "COMEDY | <b> NINA </b> You were good. <b> KIRK </b> Yes, I was. The first few days were, I don't know, boring. Nina looks relieved. <b> NINA </b> And the last one was cold and unforgiving. You know... <b> KIRK </b> What was I thinking? <b> NINA </b> What? <b> KIRK </b> I don't know. Maybe I didn't really understand anything. She looks at him a moment. <b> NINA </b> You slept? <b> KIRK </b> No. <b> NINA </b> Good. You look really good tonight. <b> KIRK </b> Thanks. <b> NINA </b> I wish I could hug you for tonight. I'll call you tomorrow. <b> KIRK </b> I might. But when I get up, I should get going. <b> NINA </b> Wait till I get in trouble. <b> KIRK </b> Yeah. Whatever. And we'll talk. I think you'll make it work out. <b> NINA </b> You bet. <b> CUT TO: </b> <b>INT. MOTEL ROOM 21 - SAME TIME </b> Nina lies still in bed, a damp blanket around her. On the bedside table sits a VHS tape, and, to her horror, Nina's CELL PHONE is ringing. She turns and picks it up. <b> NINA </b> (into phone) Yes? <b> MAN'S VOICE (O.S.) </b> (quietly distorted) She was asleep. <b> NINA </b> Wha? <b> MAN'S VOICE (O.S.) </b> (cheerful, sweet) Just getting a text message from my fucking boyfriend. Please don't be alarmed. Nina stares at the receiver a moment, then rolls out of bed. <b>INT. MOTEL ROOM 21 - LATER </b> The portable phone lies on the nightstand by Nina's bed. Nina starts typing on her laptop, as a guest lounge. <b> DISSOLVE TO: </b> <b>INT. MOTEL ROOM 21 - LATER </b> Nina's sitting on the edge of her bed, typing... <b> DISSOLVE TO: </b> <b>INT. MOTEL ROOM 21 - LATER </b> Nina finishes typing. <b> DISSOLVE TO: </b> <b>INT. MOTEL ROOM 21 - SAME TIME </b> Nina glances at the clock. 5:00. She picks up the phone, sits up and looks around, taking in the room. The bed is completely empty. She flips it open, picks up her bag, and heads for the door. <b> DISSOLVE TO: </b> <b>INT. MOTEL ROOM 21 - MOMENTS LATER </b> Nina comes back out, still typing. <b> DISSOLVE TO: </b> <b>INT. MOTEL ROOM 21 - LATER </b> Nina walks into the room, looking around, exhausted. \n",
            "COMEDY | <b> NINA </b> Sorry. It's the bed. I gotta pee. <b> MAN'S VOICE (O.S.) </b> (cheerily distorted) She was asleep. <b> NINA </\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above model generated garbage outputs about 3/8 of the times I ran it, it generated repetitive output 2/8 times I ran it, but on the other 3/8 times it generated solid movie scripts."
      ],
      "metadata": {
        "id": "wsqNsN4_zQ2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try **top_k = 5**:"
      ],
      "metadata": {
        "id": "N5TangBNzxhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "#prompt = \"<|startoftext|>\" # if I include this in the prompt, it generates garbage\n",
        "genre_name = \"COMEDY\"\n",
        "#prompt += \" \" + genre_name + \" | \"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=5, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  # debug prints\n",
        "  #print(\"sample_outputs:\")\n",
        "  #print(sample_outputs)\n",
        "  #print(\"sample_outputs[0]:\")\n",
        "  #print(sample_outputs[0])\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  try:\n",
        "    prompt = genre_name + sample_output_decoded_parts[2]\n",
        "  except: # on this rare occasion, GPT-2 didn't generate the second genre_name in the middle of the generated sequence\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_after_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[half_sample_output_decoded_tokens_length:sample_output_decoded_tokens_length]:\n",
        "      prompt_after_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints\n",
        "    #print(\"prompt_after_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_after_genre_name_and_vertical_line)\n",
        "    prompt = genre_name + \" | \" + prompt_after_genre_name_and_vertical_line\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "vZGEHDHYxVIZ",
        "outputId": "77e4114b-d9ce-4a56-b199-83f26d1b6d83"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY |  \n",
            "COMEDY |   \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-e72fd7fa7c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# print the last part of the last generated line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: the above approach generated garbage outputs most of the time (I ran it about 4 times)"
      ],
      "metadata": {
        "id": "mWTO8urT0NPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try **top_k = 1**:"
      ],
      "metadata": {
        "id": "Cr3STF4c0Sci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "#prompt = \"<|startoftext|>\" # if I include this in the prompt, it generates garbage\n",
        "genre_name = \"COMEDY\"\n",
        "#prompt += \" \" + genre_name + \" | \"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=1, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  # debug prints\n",
        "  #print(\"sample_outputs:\")\n",
        "  #print(sample_outputs)\n",
        "  #print(\"sample_outputs[0]:\")\n",
        "  #print(sample_outputs[0])\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  try:\n",
        "    prompt = genre_name + sample_output_decoded_parts[2]\n",
        "  except: # on this rare occasion, GPT-2 didn't generate the second genre_name in the middle of the generated sequence\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_after_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[half_sample_output_decoded_tokens_length:sample_output_decoded_tokens_length]:\n",
        "      prompt_after_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints\n",
        "    #print(\"prompt_after_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_after_genre_name_and_vertical_line)\n",
        "    prompt = genre_name + \" | \" + prompt_after_genre_name_and_vertical_line\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "wvor1D9Jz1co",
        "outputId": "53565269-8196-4880-b47d-3cfa95962a04"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY |  \n",
            "COMEDY |   \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n",
            "COMEDY |    \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-2c2da33d44ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# print the last part of the last generated line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: the above approach generated garbage outputs all of the time (I ran it 3 times)"
      ],
      "metadata": {
        "id": "xD7dD3wh0ZIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try a different prompt structure (**half of the generated movie line | genre name**) with **top_k = 100**:"
      ],
      "metadata": {
        "id": "j5xc9CFf0fxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "genre_name = \"COMEDY\"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints below\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints below\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=100, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded:\")\n",
        "  #print(sample_output_decoded)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  prompt = sample_output_decoded_parts[1][2:] + \" \" + genre_name + \" | \" # the sample_output_decoded_parts[1][2:] gets rid\n",
        "                                                                         # of the \" | \"\n",
        "\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  \n",
        "  if (len(sample_output_decoded_parts) == 2): # the midway genre tag wasn't generated\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_before_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[:half_sample_output_decoded_tokens_length]:\n",
        "      prompt_before_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints below\n",
        "    #print(\"prompt_before_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_before_genre_name_and_vertical_line)\n",
        "    if (prompt_before_genre_name_and_vertical_line != genre_name + \" | \"):\n",
        "      prompt = prompt_before_genre_name_and_vertical_line + genre_name + \" | \" # avoids duplicating the genre tag and the vertical line\n",
        "    else:\n",
        "      prompt = genre_name + \" | \"\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + \" | \" + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz_BJgT80ixG",
        "outputId": "f7443750-714a-4ec2-8ebd-1d12b6f8203c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY \n",
            " COMEDY |  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " COMEDY \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " COMEDY |????? What kind of website are you? <b> DILLON </b> Oh. Um, uh, I'd like to say that one of my favorite games is called Monkey over: Do you have your phone or phone? <b> TERRY </b> Ok, so I've decided to throw away my phone and go to work. And it's been a while and I thought I'd just hang up and let the guys devour this new thing and go at it from the first minute it's gonna start. I mean, I like the story a lot. It's like, a little bit different from the other games. <b> TERRY </b> Oh? <b> DILLON </b> You know what? I've never played a video game in my whole life. It takes a really long time. And when you play it, you know, you know, like a hundred times. And I've got to make it really painful for my friends. I don't have a lot of friends. Terry looks stunned. <b> TERRY </b> I love you. <b> </b> <b> </b> <b> </b> <b> </b> <b> 79. </b> <b> TERRY/DILLON </b> It's ok. I like you. But, uh... there's just so many feelings. <b> DILLON </b> Uh-huh. I think we should go have lunch or something. Or something. <b> TERRY </b> Okay, I, I mean, what do you want to do with my life? Terry walks into the back of the restaurant to get his cigarettes. <b> TERRY (CONT'D) </b> What do you want to do with my life? He turns around and sees his date. <b> TERRY (CONT'D) </b> Hi. <b> SKIP </b> <b> TERRY </b> (to waitress) Hey. <b> SKIP </b> She just looks at him. <b> TERRY </b> Skipper, where are you? <b> SKIP </b> This is a big restaurant, isn't it? <b> TERRY </b> Oh, okay. We can't stay here. <b> SKIP </b> Come on. It's cool. I'm Sky. <b> TERRY </b> I'm Skipper, am I? I'm Sky. <b> SKIP </b> Um, hi. <b> </b> <b> </b> <b> </b> <b> </b> <b> 80. </b> <b> TERRY </b> Yeah. The Waitress approaches and they speak in hushed tones. <b> SKIP </b> Did I make a mistake? <b> TERRY </b> No. <b> SKIP </b> Should I? <b> TERRY </b> Um, yeah. We, uh, we do have something special to go over. With dinner. \n",
            "????? What kind of website are you? <b> DILLON </b> Oh. Um, uh, I'd like to say that one of my favorite games is called Monkey over: Do you have your phone or phone? <b> TERRY </b> Ok, so I've decided to throw away my phone and go to work. And it's been a while and I thought I'd just hang up and let the guys devour this new thing and go at it from the first minute it's gonna start. I mean, I like the story a lot. It's like, a little bit different from the other games. <b> TERRY </b> Oh? <b> DILLON </b> You know what? I've never played a video game in my whole life. It takes a really long time. And when you play it, you know, you know, like a hundred times. And I've got to make it really painful for my friends. I don't have a lot of friends. Terry looks stunned. <b> TERRY </b> I love you. <b> </b> <b> </b> <b> </b> <b> </b> <b> 79. </b> <b> TERRY/DILLON </b> It's ok. I like you. But, uh... there's just so many feelings. <b> DILLON </b> Uh-huh. I think we should go have lunch or something. Or something. <b> TERRY </b> Okay, I, I mean, what do you want to do with my life? Terry walks into the back of the restaurant to get his cigarettes. <b> TERRY (CONT'D) </b> What do you want to do with my life? He turns around and sees his date. <b> TERRY (CONT'D) </b> Hi. <b> SKIP </b> <b> TERRY </b> (to waitress) Hey. <b> SKIP </b> She just looks at him. <b> TERRY </b> Skipper, where are you? <b> SKIP </b> This is a big restaurant, isn't it? <b> TERRY </b> Oh, okay. We can't stay here. <b> SKIP </b> Come on. It's cool. I'm Sky. <b> TERRY </b> I'm Skipper, am I? I'm Sky. <b> SKIP </b> Um, hi. <b> </b> <b> </b> <b> </b> <b> </b> <b> 80. </b> <b> TERRY </b> Yeah. The Waitress approaches and they speak in hushed tones. <b> SKIP </b> Did I make a mistake? <b> TERRY </b> No. <b> SKIP </b> Should I? <b> TERRY </b> Um, yeah. We, uh, we do have something special to go over. With dinner.  COMEDY | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "????? What kind of website are you? <b> DILLON </b> Oh. Um, uh, I'd like to say that one of my favorite games is called Monkey over: Do you have your phone or phone? <b> TERRY </b> Ok, so I've decided to throw away my phone and go to work. And it's been a while and I thought I'd just hang up and let the guys devour this new thing and go at it from the first minute it's gonna start. I mean, I like the story a lot. It's like, a little bit different from the other games. <b> TERRY </b> Oh? <b> DILLON </b> You know what? I've never played a video game in my whole life. It takes a really long time. And when you play it, you know, you know, like a hundred times. And I've got to make it really painful for my friends. I don't have a lot of friends. Terry looks stunned. <b> TERRY </b> I love you. <b> </b> <b> </b> <b> </b> <b> </b> <b> 79. </b> <b> TERRY/DILLON </b> It's ok. I like you. But, uh... there's just so many feelings. <b> DILLON COMEDY | iewu> Yeah? I've been so lonely and out lately, so I'm really happy to have you over to spend time with me in my apartment. <b> TERRY </b> Yeah, I've always wanted to talk to you but I really think this is kind of a good time to open and let you know. <b> TERRY/DILLON </b> Yeah? And what do you think? <b> TERRY </b> Well, I think I wanna talk about something. Like, something. <b> DILLON </b> Oh. Well, OK. Maybe it's just, uh, something. <b> TERRY </b> Right. I think it's interesting. I think it's cool. <b> DILLON </b> Are you sure? <b> TERRY </b> I think it's a great idea. It really helps. You know, I think it is a good time to open and let you know what I think. But right now I'm kind of nervous. I'm just sort of tense. It's like, like, like, this really important day is getting to know you, right? So it's like... <b> </b> <b> </b> <b> </b> <b> </b> <b> 80. </b> But then, uh, I don't know how to say \"hi\". So I can't tell you what you think is cool, or whatever, right? <b> TERRY </b> Uh... actually. I think good thoughts. Good thoughts. ROMANCE | <b> DILLON </b> Oh. Yeah. You know, I have an idea. Are you going to come over? Have a good time? <b> TERRY </b> Yeah, I'm really busy right now. They share a quiet moment. <b> TERRY </b> Can I come over? I mean, you know? This is the best place to spend the day. <b> DILLON </b> Absolutely. <b> TERRY </b> Yeah, okay. Really cool. Bye. Terry walks off. Dellon watches him go. He then realizes he should continue this\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "????? What kind of website are you? <b> DILLON </b> Oh. Um, uh, I'd like to say that one of my favorite games is called Monkey over: Do you have your phone or phone? <b> TERRY </b> Ok, so I've decided to throw away my phone and go to work. And it's been a while and I thought I'd just hang up and let the guys devour this new thing and go at it from the first minute it's gonna start. I mean, I like the story a lot. It's like, a little bit different from the other games. <b> TERRY </b> Oh? <b> DILLON </b> You know what? I've never played a video game in my whole life. It takes a really long time. And when you play it, you know, you know, like a hundred times. And I've got to make it really painful for my friends. I don't have a lot of friends. Terry looks stunned. <b> TERRY </b> I love you. <b> </b> <b> </b> <b> </b> <b> </b> <b> 79. </b> <b> TERRY/DILLON </b> It's ok. I like you. But, uh... there's just so many feelings. <b> DILLON COMEDY | iewu> Yeah? I've been so lonely and out lately, so I'm really happy to have you over to spend time with me in my apartment. <b> TERRY </b> Yeah, I've always wanted to talk to you but I really think this is kind of a good time to \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iewu> Yeah? I've been so lonely and out lately, so I'm really happy to have you over to spend time with me in my apartment. <b> TERRY </b> Yeah, I've always wanted to talk to you but I really think this is kind of a good time to  COMEDY | �� you know, be happy because I know I already have an apartment of my own. And I also like you, being there when I have a drink at six. So I'm really gonna write this down for you tomorrow night. Can I ever write my name down? <b> LILA </b> I think so, so. Terry sits up, glancing at the calendar. <b> TERRY </b> Do you know what time it is? <b> LILA </b> Actually, it's four-thirty. And you're gonna be late today. Just then, a very curious Maid comes in, walks over to Terry and kisses him on the cheek. <b> MAID </b> Hi! Terry, you ready for the present? <b> TERRY </b> Sure, I am. <b> MAID </b> Great meeting you. The Maid and the Maid walk on, as Terry walks back into his apartment. <b> CUT TO: </b> <b> THE MAID </b> I'm so happy we both have dinner. <b> INT. TERRY'S APARTMENT � LATER </b> Terry goes into his apartment. <b> TERRY </b> Well, this is what it looks like to do. Here, this is one of those big weddings, lots of neat towels, you know... <b> MAID </b> I know what it looks like. I'm so happy and excited to be married, and I've just felt it for a while. It's like a great big love affair, y'know. And, uh, we're actually doing the wedding of our first child and living together out here in a very big part of the country � with you. That's kind of the big part of it, y'know? They just feel so good. It's just so... <b> TERRY </b> Yeah, yeah, but, uh, it's like a big family. <b> MAID </b> It's so big, y'know? <b> TERRY </b> Yeah, I know. <b> MAID </b> Yeah, and it's like, a baby's birthday, y'know, and we're going to do the wedding thing. It's like, a baby-sitting wedding. Y'know, and then this, y'know, and the whole whole thing, it's like a big happy family, y'know. I have so much fun with all those guys that dress like that. <b> TERRY </b> Yeah. <b> MAID </b> ROMANCE | Yeah. <b> TERRY </b> Oh, my God, it's good to be married. <b> MAID </b> You mean, I'm not even sure we're really doing the wedding thing right now, y'know, but, y'know, I know we are. <b> TERRY </b> You are. <b> MAID </b> You know, it just feels good. <b> TERRY </b> Yeah. It just seems like a whole lot more fun. <b> MAID </b> I'm sorry, you guys don't have anything to say. <b> TERRY </b> Yeah. I just\n",
            " iewu> Yeah? I've been so lonely and out lately, so I'm really happy to have you over to spend time with me in my apartment. <b> TERRY </b> Yeah, I've always wanted to talk to you but I really think this is kind of a good time to  COMEDY | �� you know, be happy because I know I already have an apartment of my own. And I also like you, being there when I have a drink at six. So I'm really gonna write this down for you tomorrow night. Can I ever write my name down? <b> LILA </b> I think so, so. Terry sits up, glancing at the calendar. <b> TERRY </b> Do you know what time it is? <b> LILA </b> Actually, it's four-thirty. And you're gonna be late today. Just then, a very curious Maid comes in, walks over to Terry and kisses him on the cheek. <b> MAID </b> Hi! Terry, you ready for the present? <b> TERRY </b> Sure, I am. <b> MAID </b> Great meeting you. The Maid and the Maid walk on, as Terry walks back into his apartment. <b> CUT TO: </b> <b> THE MAID </b> I'm so happy we both have dinner. <b> INT. TERRY'S APARTMENT � LATER </b> Terry goes into his apartment. <b> TERRY </b> Well, this is what it looks like to do. Here, this is one of those big weddings, lots of neat towels, you know... <b> \n",
            "COMEDY |  | �� A SMALL BOY </b> The Maid looks down at her Maid. <b> MAID </b> Oh, wow! I almost forgot! I think this one's perfect for you! I think you should come with me. We have so much together! <b> TERRY </b> Yeah, I know what's great! I get it! <b> MAID </b> Oh, that sounds great. No problem. <b> TERRY </b> Yeah, of course! Yeah! Great. I like you. I really like you too, you know? <b> MAID </b> Well, uh, we're both at a loss for words. We both have my parents here -- he is such a nice guy. <b> TERRY </b> Oh, yeah? Well, what's my dad like? His cool? Yeah, he does, uh, like a social worker. <b> MAID </b> I don't know, he wants to be social worker, y'know, but to be social worker? <b> TERRY </b> Y'know, yeah. I guess that's a very good idea. <b> MAID </b> I feel like we're starting out badly today, I \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above code generates repetitive output (tested ~4 times)"
      ],
      "metadata": {
        "id": "CiQJBCbS4PcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try **top_k = 10**:"
      ],
      "metadata": {
        "id": "2A7MaIfX4UMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "genre_name = \"COMEDY\"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints below\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints below\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=10, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded:\")\n",
        "  #print(sample_output_decoded)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  prompt = sample_output_decoded_parts[1][2:] + \" \" + genre_name + \" | \" # the sample_output_decoded_parts[1][2:] gets rid\n",
        "                                                                         # of the \" | \"\n",
        "\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  \n",
        "  if (len(sample_output_decoded_parts) == 2): # the midway genre tag wasn't generated\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_before_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[:half_sample_output_decoded_tokens_length]:\n",
        "      prompt_before_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints below\n",
        "    #print(\"prompt_before_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_before_genre_name_and_vertical_line)\n",
        "    if (prompt_before_genre_name_and_vertical_line != genre_name + \" | \"):\n",
        "      prompt = prompt_before_genre_name_and_vertical_line + genre_name + \" | \" # avoids duplicating the genre tag and the vertical line\n",
        "    else:\n",
        "      prompt = genre_name + \" | \"\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + \" | \" + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "PQILfYiD4W50",
        "outputId": "883ebd49-d125-42ae-fb9b-2579bebfad67"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | \n",
            "COMEDY \n",
            " COMEDY |  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " COMEDY \n",
            " COMEDY |  \n",
            " COMEDY \n",
            " COMEDY |  \n",
            " COMEDY \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " COMEDY | iz, it's not the same, but it's the same. And you're a smart man, and you're a smart person, and you're a smart person is... and I am. And that's exactly what I am, because I am the smartest person I've ever met, because I know where I want to go someday. But I'm not going to be a smart person. I'm going to be a jerk. And I'm not going to be a jerk. I'm not going to be a jerk. You're not going to be a jerk. I am a jerk. And I'm not going to be a jerk. I'm not going to be a jerk. I'm not going to be a jerk. (then) And you're not going to be a jerk. And you're not going to be a jerk. I'm not going to be a jerk. And I'm not going to be a jerk. You are not going to be a jerk. You are not going to be a jerk. <b> </b> <b> </b> <b> </b> <b> </b> <b> 7. </b> The door is slammed hard, and a tall, dark figure with a fedora is flung through it. He is, indeed, the stranger. <b> INT. LOBBY, HOTEL LOUNGE - EVENING </b> The man in the fedora is being buffeted by the hotel guests, and he seems to be buffeted by a hostess. <b> HOTEL SERVANT </b> You are very welcome, Mr. Benedict. <b> BENEDICT </b> Hello. <b> HOTEL SERVANT </b> (to the room) Thank you, Mr. Benedict, for your time. He leaves. The hostess is left staring at him. A moment later the elevator doors open to admit the arrival of the President of the United States. He is followed by several dignitaries, including Pierre and several ranking officials, including the Ambassador of Japan and the Vice-President of France. <b> INT. PRESIDENT OF THE UNITED STATES - CONTINUOUS ACTION </b> The President of the United States, followed by his entourage, walks toward the valet stand. As he gets close to the stand he notices that his hands have been bandaged. <b> PRESIDENT OF THE UNITED STATES </b> (in Japanese, subtitled) I don't know where I am, but I'm certainly not in the mood for being here. The CAMERA PULLS BACK and we see that the \n",
            " iz, it's not the same, but it's the same. And you're a smart man, and you're a smart person, and you're a smart person is... and I am. And that's exactly what I am, because I am the smartest person I've ever met, because I know where I want to go someday. But I'm not going to be a smart person. I'm going to be a jerk. And I'm not going to be a jerk. I'm not going to be a jerk. You're not going to be a jerk. I am a jerk. And I'm not going to be a jerk. I'm not going to be a jerk. I'm not going to be a jerk. (then) And you're not going to be a jerk. And you're not going to be a jerk. I'm not going to be a jerk. And I'm not going to be a jerk. You are not going to be a jerk. You are not going to be a jerk. <b> </b> <b> </b> <b> </b> <b> </b> <b> 7. </b> The door is slammed hard, and a tall, dark figure with a fedora is flung through it. He is, indeed, the stranger. <b> INT. LOBBY, HOTEL LOUNGE - EVENING </b> The man in the fedora is being buffeted by the hotel guests, and he seems to be buffeted by a hostess. <b> HOTEL SERVANT </b> You are very welcome, Mr. Benedict. <b> BENEDICT </b> Hello. <b> HOTEL SERVANT </b> (to the room) Thank you, Mr. Benedict, for your time. He leaves. The hostess is left staring at him. A moment later the elevator doors open to admit the arrival of the President of the United States. He is followed by several dignitaries, including Pierre and several ranking officials, including the Ambassador of Japan and the Vice-President of France. <b> INT. PRESIDENT OF THE UNITED STATES - CONTINUOUS ACTION </b> The President of the United States, followed by his entourage, walks toward the valet stand. As he gets close to the stand he notices that his hands have been bandaged. <b> PRESIDENT OF THE UNITED STATES </b> (in Japanese, subtitled) I don't know where I am, but I'm certainly not in the mood for being here. The CAMERA PULLS BACK and we see that the  COMEDY | urchin is actually the Japanese Minister, Sadako. She is a statue of courage and courage. She is a vision of strength and courage. <b> EXT. HOTEL - EVENING </b> The Japanese Ambassador, Sadako, and the President, accompanied by a ROMANCE | dozen or so Japanese dignitaries, walk up to the valet stand. Sadako bows. <b> SADAKO </b> Good morning. <b> PRESIDENT OF THE UNITED STATES </b> May I have your attention, please. Sadako is Japanese, and very proud. She bows. The President looks up and bows back. <b> </b> <b> </b> <b> </b> <b> </b> <b> 8. </b> <b> EXT. HOTEL POOL, AMERICAN TOWN - MORNING </b> A typical typical American town with a huge, modernistic highrise hotel. The Japanese Ambassador is escorted by a dozen Japanese businessmen and Japanese businessmen. Sadako bows. The President of the United States,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-571322fc9f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# print the last part of the last generated line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" | \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above code generates repetitive output (tested ~4 times)"
      ],
      "metadata": {
        "id": "3RW_X_eT5CGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try **top_k = 5**:"
      ],
      "metadata": {
        "id": "hyw2-59z5DAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "genre_name = \"COMEDY\"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints below\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints below\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=5, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded:\")\n",
        "  #print(sample_output_decoded)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  prompt = sample_output_decoded_parts[1][2:] + \" \" + genre_name + \" | \" # the sample_output_decoded_parts[1][2:] gets rid\n",
        "                                                                         # of the \" | \"\n",
        "\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  \n",
        "  if (len(sample_output_decoded_parts) == 2): # the midway genre tag wasn't generated\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_before_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[:half_sample_output_decoded_tokens_length]:\n",
        "      prompt_before_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints below\n",
        "    #print(\"prompt_before_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_before_genre_name_and_vertical_line)\n",
        "    if (prompt_before_genre_name_and_vertical_line != genre_name + \" | \"):\n",
        "      prompt = prompt_before_genre_name_and_vertical_line + genre_name + \" | \" # avoids duplicating the genre tag and the vertical line\n",
        "    else:\n",
        "      prompt = genre_name + \" | \"\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + \" | \" + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OoCkizd5Ff3",
        "outputId": "7a508511-8131-4d95-af2b-ad9cc374adca"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY |  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | iz, you know, I mean, you know, you know, you know... <b> </b><b> </b> [The two of them are standing in front of the building. They have obviously just come out.] <b> </b><b>? 651? </b><b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> (tentatively) <b> </b> Hello. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> (tentatively) <b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b> (to her) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning. <b> </b><b> MARK </b><b> </b> Good morning, Jane. <b> </b><b> </b> They both start walking toward the entrance, but Mark is not in front of them. He is standing in the entrance way between two doors. <b> </b><b> JANE </b><b> </b> Mark, I'm sorry to bother you. <b> </b><b> MARK </b><b> </b> Yes. <b> </b> (he stops in front of her, and looks at her) <b> </b> You know, I think we should get going, and we should have a talk. <b> </b><b> JANE </b><b> </b> Oh, yes, of course. <b> </b> He starts walking toward the entrance. <b> </b><b> </b><b> JANE </b><b> </b> Oh, no, I can't, I can't. I'll have to get to the door. <b> </b> (she stops and stands still. Mark looks at her, and then turns toward him, then he walks away, then he stops in front of her. He looks at her and then at the door, and then he walks back to the entranceway and opens the door to his room. He looks around and then at the two of them, then at the open door. He walks out into the hall, and the two of them walk into the hall, and the camera follows after Mark. <b> </b><b> </b><b> </b> [The camera is at the door to his room, and Mark has just closed it. The door opens and the three of them come out into the hallway, and Mark walks toward the hall, and he walks to the door to his room. He looks around, and then at his door, and then at the door, and then at his door, and then at his room and then at his door. He looks around, and then at his door, and then at his door. Then he looks at his door. He looks at his door, and then at his door. He looks at his door and then at his door. Then at his door, and then at his door, and then at his door\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY | iz, you know, I mean, you know, you know, you know... <b> </b><b> </b> [The two of them are standing in front of the building. They have obviously just come out.] <b> </b><b>? 651? </b><b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> (tentatively) <b> </b> Hello. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> (tentatively) <b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b> (to her) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning. <b> </b><b> MARK </b><b> </b> Good morning, Jane. <b> </b><b> </b> They both start walking toward the entrance, but Mark is not in front of them. He is standing in the entrance way between two doors. <b> </b><b> JANE </b><b> </b> Mark, I'm sorry to bother you. <b> </b><b> MARK </b><b> </b> Yes. <b> </b> (he stops in front of her, and looks at her) <b> </b> You know, I think we should get going, and we should have a talk. <b> </b><b> JANE </b><b> </b> Oh, yes, of course. <b> </b> He starts walking toward the entrance. <b> </b><b> </b><b> JANE </b><b> </b> Oh, no, I can't, I can't. I'll have to get to \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iz, you know, I mean, you know, you know, you know... <b> </b><b> </b> [The two of them are standing in front of the building. They have obviously just come out.] <b> </b><b>? 651? </b><b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> (tentatively) <b> </b> Hello. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> (tentatively) <b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b> (to her) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning. <b> </b><b> MARK </b><b> </b> Good morning, Jane. <b> </b><b> </b> They both start walking toward the entrance, but Mark is not in front of them. He is standing in the entrance way between two doors. <b> </b><b> JANE </b><b> </b> Mark, I'm sorry to bother you. <b> </b><b> MARK </b><b> </b> Yes. <b> </b> (he stops in front of her, and looks at her) <b> </b> You know, I think we should get going, and we should have a talk. <b> </b><b> JANE </b><b> </b> Oh, yes, of course. <b> </b> He starts walking toward the entrance. <b> </b><b> </b><b> JANE </b><b> </b> Oh, no, I can't, I can't. I'll have to get to  COMEDY |!!! <b> </b><b> MARK </b><b> </b> I'm so sorry. <b> </b><b> JANE </b><b> </b> I'll get to you in a little while. I'm sorry. <b> </b><b> MARK </b><b> </b> I'm sorry. <b> </b> (he stops in front of her) <b> </b> I'm so sorry, Jane. <b> </b><b> JANE </b><b> </b> I'm so sorry. <b> </b><b> MARK </b><b> </b> I'm sorry. <b> </b><b> JANE </b><b> </b> I'm so sorry. <b> </b> (he stops in front of her again) <b> </b> I'll get to you in a little while, Mark. <b> </b><b> MARK </b><b> </b> Of course, of course. <b> </b> (he stops in front of her again) <b> </b> I'm sorry. <b> </b> (he stops in front of her again)\n",
            " iz, you know, I mean, you know, you know, you know... <b> </b><b> </b> [The two of them are standing in front of the building. They have obviously just come out.] <b> </b><b>? 651? </b><b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> (tentatively) <b> </b> Hello. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> (tentatively) <b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b> (to her) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning. <b> </b><b> MARK </b><b> </b> Good morning, Jane. <b> </b><b> </b> They both start walking toward the entrance, but Mark is not in front of them. He is standing in the entrance way between two doors. <b> </b><b> JANE </b><b> </b> Mark, I'm sorry to bother you. <b> </b><b> MARK </b><b> </b> Yes. <b> </b> (he stops in front of her, and looks at her) <b> </b> COMEDY |  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iz, you know, I mean, you know, you know, you know... <b> </b><b> </b> [The two of them are standing in front of the building. They have obviously just come out.] <b> </b><b>? 651? </b><b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> (tentatively) <b> </b> Hello. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> (tentatively) <b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b> (to her) <b> </b> Hello, COMEDY | ian. <b> </b> Mark turns round. <b> </b><b> MARK </b><b> </b> Hello. <b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to Mark) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Good morning. <b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to the two of them) <b> </b> Hello, Mark. <b> </b> They all look at her. <b> </b><b> MARK </b><b> </b> Good morning. <b> </b><b> JANE </b><b> </b> Good morning. <b> </b><b> MARK </b><b> </b> Good morning, Amy. <b> </b> They all sit down in front of her, and Mark is very uncomfortable. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b><b> MARK </b><b> </b> Good morning, Amy. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b><b> MARK </b><b> </b> Good morning, Amy. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b><b> MARK </b><b> </b> Good morning, Amy. <b> </b> Mark looks at her, and then smiles. <b> </b><b> MARK </b><b> </b> Good morning, Amy. <b> </b> (to the two of them) <b> </b> Good morning, Mark. <b> </b><b> MARK </b><b> </b> Good morning. <b> </b> They sit there for a while, and then he goes back to his paper work, and then turns to Jane again. <b> </b><b> MARK </b><b> </b> Good morning, Jane. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iz, you know, I mean, you know, you know, you know... <b> </b><b> </b> [The two of them are standing in front of the building. They have obviously just come out.] <b> </b><b>? 651? </b><b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> (tentatively) <b> </b> Hello. <b> </b><b> MARK </b><b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> (tentatively) <b> </b> Hello, Jane. <b> </b><b> JANE </b><b> </b> Good morning, Mark. <b> </b> (to her) <b> </b> Hello, COMEDY | ian. <b> </b> Mark turns round. <b> </b><b> MARK </b><b> </b> Hello. <b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to Mark) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Good morning. <b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to the two of them) <b> </b> Hello, Mark. <b> </b> They all look at her. <b> </b><b> MARK </b><b> </b> Good morning. \n",
            " ian. <b> </b> Mark turns round. <b> </b><b> MARK </b><b> </b> Hello. <b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to Mark) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Good morning. <b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to the two of them) <b> </b> Hello, Mark. <b> </b> They all look at her. <b> </b><b> MARK </b><b> </b> Good morning.  COMEDY | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ian. <b> </b> Mark turns round. <b> </b><b> MARK </b><b> </b> Hello. <b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to Mark) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Good COMEDY | iz! <b> </b><b> JANE </b><b> </b> You are? <b> </b><b> MARK </b><b> </b> Yes. <b> </b><b> JANE </b><b> </b> Oh! <b> </b><b> MARK </b><b> </b> Well, you know, I've got some new stuff to do. <b> </b><b> JANE </b><b> </b> Oh, I see. Well - well - well - well - well - well! <b> </b><b> MARK </b><b> </b> Well - well, well, well - I hope you like your new stuff. <b> </b><b> JANE </b><b> </b> Oh! <b> </b> (turning to Mark) <b> </b> Well, Mark! You're really great. <b> </b><b> MARK </b><b> </b> Well, I've got to go now. <b> </b><b> JANE </b><b> </b> Well, I'm certainly going. I have to get back to the office. <b> </b><b> MARK </b><b> </b> No, I don't think so. <b> </b><b> JANE </b><b> </b> Well, then I'll see you later then. <b> </b><b> MARK </b><b> </b> Oh! <b> </b> He walks out of the room, and then turns back to the window. <b> </b><b> MARK </b><b> </b> Goodbye. <b> </b> He turns and walks to the door, and looks out. He turns and looks out the window. Then suddenly, he looks down. <b> </b><b>? 653? </b><b> </b><b> MARK </b><b> </b> I've got to get back to the office. <b> </b><b> </b><b> JANE </b><b> </b> Oh, I see. <b> </b><b> </b><b> JANE </b><b> </b> Oh! <b> </b><b> </b> She walks out of the room. Mark looks around for his office. He turns and walks over to his office. He looks at the open door to his office, and then turns to look at the window. <b> </b><b> JANE </b><b> </b> Oh! <b> </b> (turning to Mark) <b> </b> I've got to get back to the office! <b> </b><b> </b><b> INT. MARK'S OFFICE - DAY </b><b> </b> Mark walks over to the window. <b> </b><b> MARK </b><b>\n",
            " ian. <b> </b> Mark turns round. <b> </b><b> MARK </b><b> </b> Hello. <b> </b><b>? 652? </b><b> </b><b> JANE </b><b> </b> Hello. <b> </b> (to Mark) <b> </b> Hello, Mark. <b> </b><b> MARK </b><b> </b> Good COMEDY | iz! <b> </b><b> JANE </b><b> </b> You are? <b> </b><b> MARK </b><b> </b> Yes. <b> </b><b> JANE </b><b> </b> Oh! <b> </b><b> MARK </b><b> </b> Well, you know, I've got some new stuff to do. <b> </b><b> JANE </b><b> </b> Oh, I see. Well - well - well - well - well - well! <b> </b><b> MARK </b><b> </b> Well - well, well, well - I hope you like your new stuff. <b> </b><b> JANE </b><b> </b> Oh! <b> </b> (turning to Mark) <b> </b> Well, Mark! You're really great. <b> </b><b> MARK </b><b> </b> Well, I've got to go now. <b> </b><b> JANE </b><b> </b> Well, I'm certainly going. I have to get back to the office. <b> </b><b> MARK </b><b> </b> No, I don't think so. <b> </b><b> JANE </b><b> </b> \n",
            "COMEDY |  | iz. <b> </b><b> MARK </b><b> </b> Yes, well - you know, it's a very busy day. <b> </b><b> JANE </b><b> </b> Oh! <b> </b><b> MARK </b><b> </b> Yeah. <b> </b> She starts walking towards the elevator. <b> </b><b> </b><b> JANE </b><b> </b> Mark - you're really great. <b> </b> She stops. <b> </b><b> MARK </b><b> </b> Oh! <b> </b> She walks towards the elevator. <b> </b><b> JANE </b><b> </b> Oh! <b> </b><b> MARK </b><b> </b> Yes. <b> </b><b> JANE </b><b> </b> Well, well, well - well - you've been wonderful to me. <b> </b><b> MARK </b><b> </b> I've been wonderful to you. <b> </b><b> JANE </b><b> </b> Well - I've been very nice to you too. <b> </b><b> MARK </b><b> </b> Well, well, well - you're very nice to me too. <b> </b> (turning to her) <b> </b> Mark! <b> </b> She walks towards the elevator.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above code generates repetitive output (tested ~4 times)"
      ],
      "metadata": {
        "id": "QBmUHcW25o4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try with **top_k = 1**:"
      ],
      "metadata": {
        "id": "9eLPVkxH5rna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE = 10\n",
        "\n",
        "genre_name = \"COMEDY\"\n",
        "prompt = genre_name + \" | \"\n",
        "\n",
        "for i in range(0, NUMBER_OF_HALF_MOVIE_SCRIPT_LINES_TO_GENERATE):\n",
        "  # debug prints below\n",
        "  #print(\"prompt:\")\n",
        "  #print(prompt)\n",
        "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  generated = generated.to(device)\n",
        "\n",
        "  # debug prints below\n",
        "  #print(generated)\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=1, \n",
        "                                max_length=768,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "  sample_output_decoded = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded:\")\n",
        "  #print(sample_output_decoded)\n",
        "  sample_output_decoded_parts = sample_output_decoded.split(genre_name)\n",
        "  # debug prints below\n",
        "  #print(\"sample_output_decoded_parts:\")\n",
        "  #print(sample_output_decoded_parts)\n",
        "  #print(\"len(sample_output_decoded_parts):\")\n",
        "  #print(len(sample_output_decoded_parts))\n",
        "  prompt = sample_output_decoded_parts[1][2:] + \" \" + genre_name + \" | \" # the sample_output_decoded_parts[1][2:] gets rid\n",
        "                                                                         # of the \" | \"\n",
        "\n",
        "  print(sample_output_decoded_parts[0] + genre_name + sample_output_decoded_parts[1])\n",
        "  \n",
        "  if (len(sample_output_decoded_parts) == 2): # the midway genre tag wasn't generated\n",
        "    sample_output_decoded_tokens = sample_output_decoded.split(\" \")\n",
        "    sample_output_decoded_tokens_length = len(sample_output_decoded_tokens)\n",
        "    half_sample_output_decoded_tokens_length = sample_output_decoded_tokens_length // 2\n",
        "    prompt_before_genre_name_and_vertical_line = \"\"\n",
        "    for token in sample_output_decoded_tokens[:half_sample_output_decoded_tokens_length]:\n",
        "      prompt_before_genre_name_and_vertical_line += token + \" \"\n",
        "    # debug prints below\n",
        "    #print(\"prompt_before_genre_name_and_vertical_line:\")\n",
        "    #print(prompt_before_genre_name_and_vertical_line)\n",
        "    if (prompt_before_genre_name_and_vertical_line != genre_name + \" | \"):\n",
        "      prompt = prompt_before_genre_name_and_vertical_line + genre_name + \" | \" # avoids duplicating the genre tag and the vertical line\n",
        "    else:\n",
        "      prompt = genre_name + \" | \"\n",
        "\n",
        "# print the last part of the last generated line\n",
        "print(genre_name + \" | \" + sample_output_decoded_parts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "DoINMxJh5urM",
        "outputId": "be02159b-a26c-4059-e71a-90ed6c75b615"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY |  \n",
            "COMEDY |  \n",
            "COMEDY |  \n",
            "COMEDY |  \n",
            "COMEDY |  \n",
            "COMEDY |  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMEDY |  \n",
            "COMEDY |  \n",
            "COMEDY |  \n",
            "COMEDY |  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-7c7b0c4ab466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# print the last part of the last generated line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" | \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_output_decoded_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: The above code generates garbage output (tested ~3 times)"
      ],
      "metadata": {
        "id": "xNNWc70l7deD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9HosFRv60ylH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}